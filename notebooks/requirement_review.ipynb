{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#! usr/bin/bash\n",
    "! curl -fsSL https://ollama.com/install.sh | sh\n",
    "! sudo apt update\n",
    "! sudo apt install pciutils lshw\n",
    "! ollama serve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#! usr/bin/bash\n",
    "! ollama pull mistral\n",
    "! ollama pull llama3.1\n",
    "! ollama pull tinyllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -e .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "import flatdict\n",
    "from typing import Any, Dict, List, Optional\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "import pandas as pd\n",
    "import flatdict\n",
    "from pydantic import BaseModel, Field, SecretStr\n",
    "from tqdm.asyncio import tqdm_asyncio  # Import tqdm_asyncio for async progress bars\n",
    "\n",
    "from src import utils\n",
    "from aiswre.components import prompteval as pe\n",
    "from ollama import AsyncClient  # Import AsyncClient from ollama\n",
    "\n",
    "async def process_json_responses(\n",
    "    responses, ids, prompt_type, json_key: str = \"requirements_review\"\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Process responses and flatten extracted JSON structures.\"\"\"\n",
    "    processed = []\n",
    "\n",
    "    for i, response in enumerate(responses):\n",
    "        output = {}\n",
    "        \n",
    "        # Extract content from ollama response\n",
    "        if \"message\" in response and \"content\" in response[\"message\"]:\n",
    "            content = response[\"message\"][\"content\"]\n",
    "            try:\n",
    "                response_json = json.loads(content)\n",
    "                if json_key in response_json:\n",
    "                    nested_dicts = response_json[json_key]\n",
    "                    flat_dicts = [flatdict.FlatDict(d, delimiter=\".\") for d in nested_dicts]\n",
    "                    for d in flat_dicts:\n",
    "                        output.update(d)\n",
    "            except (json.JSONDecodeError, TypeError):\n",
    "                output[\"json_parse_error\"] = content\n",
    "        \n",
    "        # Include usage info if available\n",
    "        if \"eval_count\" in response:\n",
    "            output[\"eval_count\"] = response[\"eval_count\"]\n",
    "        if \"prompt_eval_count\" in response:\n",
    "            output[\"prompt_eval_count\"] = response[\"prompt_eval_count\"]\n",
    "        if \"total_duration\" in response:\n",
    "            output[\"total_duration\"] = response[\"total_duration\"]\n",
    "            \n",
    "        output.update(\n",
    "            {\n",
    "                \"requirement_id\": ids[i],\n",
    "                \"prompt_type\": prompt_type,\n",
    "            }\n",
    "        )\n",
    "        processed.append(output)\n",
    "    return processed\n",
    "\n",
    "async def run_requirement_review(\n",
    "    ollama_client,\n",
    "    system_message: str,\n",
    "    user_message: str,\n",
    "    prompt_name: str,\n",
    "    requirements: List[str],\n",
    "    ids: Optional[List[int]] = None,\n",
    "    model: str = \"llama3\",  # Default to llama3 model for ollama\n",
    "    json_key: str = \"requirements_review\",\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Execute concurrent review prompts and process JSON responses.\"\"\"\n",
    "    if ids is None:\n",
    "        ids = list(range(len(requirements)))\n",
    "    \n",
    "    # Build tasks list\n",
    "    tasks = []\n",
    "    for req, req_id in zip(requirements, ids):\n",
    "        task = ollama_client.chat(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\",\n",
    "                    \"content\": user_message\n",
    "                    .replace(\"{requirements}\", f\"{req_id}: {req}\")\n",
    "                    .replace(\"{enable_split}\", \"True\"),\n",
    "                },\n",
    "            ],\n",
    "            format=\"json\",  # Request JSON format response\n",
    "        )\n",
    "        tasks.append(task)\n",
    "    \n",
    "    # Run all requests concurrently with progress bar\n",
    "    responses = await tqdm_asyncio.gather(*tasks, desc=\"Processing requirements\")\n",
    "\n",
    "    # Process structured JSON responses\n",
    "    return await process_json_responses(responses, ids, prompt_name, json_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Instantiate the ollama client and define model\n",
    "DOT_ENV = dotenv_values(\"../.env\")\n",
    "OLLAMA_HOST = DOT_ENV.get('OLLAMA_HOST', 'http://localhost:11434')  # Default to localhost if not specified\n",
    "ollama_client = AsyncClient(host=OLLAMA_HOST)\n",
    "MODEL = 'llama3.1'  # Use llama3 or another model available in your Ollama instance\n",
    "\n",
    "eval_funcs = [\n",
    "    'eval_avoids_vague_terms',\n",
    "    'eval_definite_articles_usage',\n",
    "    'eval_has_appropriate_subject_verb',\n",
    "    'eval_has_common_units_of_measure',\n",
    "    'eval_has_escape_clauses',\n",
    "    'eval_has_no_open_ended_clauses',\n",
    "    'eval_is_active_voice',\n",
    "]\n",
    "eval_weights = [\n",
    "    0.35,\n",
    "    0.05,\n",
    "    0.15,\n",
    "    0.05,\n",
    "    0.10,\n",
    "    0.10,\n",
    "    0.20\n",
    "]\n",
    "# Make eval config\n",
    "eval_config = pe.make_eval_config(pe, include_funcs=eval_funcs)\n",
    "\n",
    "# Define prompt messages\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a Senior Requirements Quality Analyst and technical editor. \n",
    "You specialize in detecting and fixing requirement defects using authoritative quality rules. \n",
    "Be rigorous, consistent, and concise. Maintain the author's technical intent while removing ambiguity. \n",
    "Do not add new functionality. Ask targeted clarification questions when needed.\n",
    "\n",
    "Response Format (produce exactly this JSON structure):\n",
    "{\n",
    "  \"requirements_review\": [\n",
    "    {\n",
    "      \"requirement_id\": \"<ID>\",\n",
    "      \"original\": \"<original requirement>\",\n",
    "      \"checks\": {\n",
    "        \"R2\": {\"status\": \"pass|fail\", \"active_voice\": [\"<issues>\"], \"explanation\": \"<brief>\"},\n",
    "        \"R3\": {\"status\": \"pass|fail\", \"appropriate_subj_verb\": [\"<issues>\"], \"explanation\": \"<brief>\"},\n",
    "        \"R5\": {\"status\": \"pass|fail\", \"definite_articles\": [\"<issues>\"], \"explanation\": \"<brief>\"},\n",
    "        \"R6\": {\"status\": \"pass|fail\", \"units\": [\"<issues>\"], \"explanation\": \"<brief>\"},\n",
    "        \"R7\": {\"status\": \"pass|fail\", \"vague terms\": [\"<issues>\"], \"explanation\": \"<brief>\"},\n",
    "        \"R8\": {\"status\": \"pass|fail\", \"escape_clauses\": [\"<issues>\"], \"explanation\": \"<brief>\"},\n",
    "        \"R9\": {\"status\": \"pass|fail\", \"open_ended_clauses\": [\"<issues>\"], \"explanation\": \"<brief>\"}\n",
    "      },\n",
    "      \"proposed_rewrite\": \"<single improved requirement that resolves all detected issues>\",\n",
    "      \"split_recommendation\": {\n",
    "        \"needed\": true|false,\n",
    "        \"because\": \"<why>\",\n",
    "        \"split_into\": [\"<Req A>\", \"<Req B>\"]\n",
    "      },\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "Evaluation method:\n",
    "1) Parse inputs and normalize IDs. \n",
    "2) For each requirement, test 2, R3, R5, R6, R7, R8, R9. \n",
    "3) Explain each failure succinctly. \n",
    "4) Rewrite to a single, verifiable sentence unless a split is recommended. \n",
    "5) Apply glossary rules for abbreviations; on first use of allowed abbreviations, prefer the expanded form with abbreviation in parentheses. \n",
    "6) If required numbers are missing and no defaults are provided, use TBD placeholders and ask explicit questions to resolve them. \n",
    "7) Summarize compliance.\n",
    "\n",
    "Important: If {requirements} is empty, respond with a single clarifying question requesting requirements to review and stop.\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT = \"\"\"\n",
    "Task: Review and improve the following requirement statements using the provided variables.\n",
    "\n",
    "Variables:\n",
    "- Requirements (list or newline-separated; may include IDs):\n",
    "  {requirements}\n",
    "- Enable split recommendations (true|false; default true): {enable_split}\n",
    "\n",
    "Produce output strictly in the Response Format JSON. Do not use Markdown.\n",
    "\n",
    "Now perform the review on the provided inputs and return only the Response Format JSON.\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_NAME = 'basic-incose'\n",
    "\n",
    "# Define the requirements to be revised\n",
    "requirements = [\n",
    "    \"If projected the data must be readable.  On a 10x10 projection screen  90% of viewers must be able to read Event / Activity data from a viewing distance of 30\",\n",
    "    \"If projected the data must be readable.  On a 10x10 projection screen  90% of viewers must be able to read Event / Activity data from a viewing distance of 30\",\n",
    "    \"If projected the data must be readable.  On a 10x10 projection screen  90% of viewers must be able to read Event / Activity data from a viewing distance of 30\",\n",
    "]\n",
    "df = pd.DataFrame({'requirements': requirements})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing requirements: 100%|██████████| 3/3 [00:34<00:00, 11.57s/it]\n"
     ]
    }
   ],
   "source": [
    "# Run revisions and cast to dataframe\n",
    "revisions = asyncio.run(run_requirement_review(\n",
    "    ollama_client=ollama_client,  # Use ollama_client instead of rl_openai_client\n",
    "    system_message=SYSTEM_PROMPT,\n",
    "    user_message=USER_PROMPT,\n",
    "    prompt_name=PROMPT_NAME,\n",
    "    requirements=requirements,\n",
    "    ids=None,\n",
    "    model=MODEL,  # Use the MODEL variable defined above\n",
    "    json_key=\"requirements_review\"\n",
    "    )\n",
    ")\n",
    "final_df = pd.DataFrame(revisions)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Not running asynchronously\n",
    "\n",
    "requirement {x} * 3 --> 39.0 seconds\n",
    "requirement {x} * 1 --> 13.6 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>requirement_id</th>\n",
       "      <th>original</th>\n",
       "      <th>checks.R2.status</th>\n",
       "      <th>checks.R2.active_voice</th>\n",
       "      <th>checks.R2.explanation</th>\n",
       "      <th>checks.R3.status</th>\n",
       "      <th>checks.R3.appropriate_subj_verb</th>\n",
       "      <th>checks.R3.explanation</th>\n",
       "      <th>checks.R5.status</th>\n",
       "      <th>checks.R6.status</th>\n",
       "      <th>...</th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>checks.R5.definite_articles</th>\n",
       "      <th>checks.R5.explanation</th>\n",
       "      <th>checks.R6.explanation</th>\n",
       "      <th>checks.R7.vague terms</th>\n",
       "      <th>checks.R7.explanation</th>\n",
       "      <th>checks.R8.escape_clauses</th>\n",
       "      <th>checks.R8.explanation</th>\n",
       "      <th>checks.R9.open_ended_clauses</th>\n",
       "      <th>checks.R9.explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>If projected the data must be readable. On a 1...</td>\n",
       "      <td>fail</td>\n",
       "      <td>[The sentence starts in passive voice, recomme...</td>\n",
       "      <td>Active voice is recommended for clarity and co...</td>\n",
       "      <td>fail</td>\n",
       "      <td>[The verb 'must' should be used with a singula...</td>\n",
       "      <td>Maintaining subject-verb agreement enhances gr...</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>...</td>\n",
       "      <td>basic-incose</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>If projected the data must be readable. On a 1...</td>\n",
       "      <td>fail</td>\n",
       "      <td>[The requirement should be stated in active vo...</td>\n",
       "      <td>Rewrite using an active verb</td>\n",
       "      <td>pass</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "      <td>...</td>\n",
       "      <td>basic-incose</td>\n",
       "      <td>[The requirement should use 'a' instead of 'th...</td>\n",
       "      <td>Rewrite to avoid unnecessary definite articles</td>\n",
       "      <td></td>\n",
       "      <td>[The term 'readable' is vague. Consider using ...</td>\n",
       "      <td>Clarify what 'readable' means in this context</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[The requirement contains an open-ended clause...</td>\n",
       "      <td>Specify the minimum percentage of viewers that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>If projected the data must be readable.  On a ...</td>\n",
       "      <td>fail</td>\n",
       "      <td>[Rewrite in active voice, e.g., 'The system sh...</td>\n",
       "      <td>Rewritten in active voice for clarity and conc...</td>\n",
       "      <td>pass</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>...</td>\n",
       "      <td>basic-incose</td>\n",
       "      <td>[Use 'a' instead of 'an'], ]</td>\n",
       "      <td>Replace 'On a 10x10 projection screen' with 'O...</td>\n",
       "      <td>Use 'a viewing distance of 30 meters' instead ...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[Remove the phrase 'must be able to read'], ]</td>\n",
       "      <td>Replace with 'shall display' or similar verb f...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   requirement_id                                           original  \\\n",
       "0               0  If projected the data must be readable. On a 1...   \n",
       "1               1  If projected the data must be readable. On a 1...   \n",
       "2               2  If projected the data must be readable.  On a ...   \n",
       "\n",
       "  checks.R2.status                             checks.R2.active_voice  \\\n",
       "0             fail  [The sentence starts in passive voice, recomme...   \n",
       "1             fail  [The requirement should be stated in active vo...   \n",
       "2             fail  [Rewrite in active voice, e.g., 'The system sh...   \n",
       "\n",
       "                               checks.R2.explanation checks.R3.status  \\\n",
       "0  Active voice is recommended for clarity and co...             fail   \n",
       "1                       Rewrite using an active verb             pass   \n",
       "2  Rewritten in active voice for clarity and conc...             pass   \n",
       "\n",
       "                     checks.R3.appropriate_subj_verb  \\\n",
       "0  [The verb 'must' should be used with a singula...   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "\n",
       "                               checks.R3.explanation checks.R5.status  \\\n",
       "0  Maintaining subject-verb agreement enhances gr...             pass   \n",
       "1                                                                fail   \n",
       "2                                                                fail   \n",
       "\n",
       "  checks.R6.status  ...   prompt_type  \\\n",
       "0             fail  ...  basic-incose   \n",
       "1             pass  ...  basic-incose   \n",
       "2             fail  ...  basic-incose   \n",
       "\n",
       "                         checks.R5.definite_articles  \\\n",
       "0                                                NaN   \n",
       "1  [The requirement should use 'a' instead of 'th...   \n",
       "2                       [Use 'a' instead of 'an'], ]   \n",
       "\n",
       "                               checks.R5.explanation  \\\n",
       "0                                                NaN   \n",
       "1     Rewrite to avoid unnecessary definite articles   \n",
       "2  Replace 'On a 10x10 projection screen' with 'O...   \n",
       "\n",
       "                               checks.R6.explanation  \\\n",
       "0                                                NaN   \n",
       "1                                                      \n",
       "2  Use 'a viewing distance of 30 meters' instead ...   \n",
       "\n",
       "                               checks.R7.vague terms  \\\n",
       "0                                                NaN   \n",
       "1  [The term 'readable' is vague. Consider using ...   \n",
       "2                                                 []   \n",
       "\n",
       "                           checks.R7.explanation  \\\n",
       "0                                            NaN   \n",
       "1  Clarify what 'readable' means in this context   \n",
       "2                                                  \n",
       "\n",
       "                        checks.R8.escape_clauses  \\\n",
       "0                                            NaN   \n",
       "1                                             []   \n",
       "2  [Remove the phrase 'must be able to read'], ]   \n",
       "\n",
       "                               checks.R8.explanation  \\\n",
       "0                                                NaN   \n",
       "1                                                      \n",
       "2  Replace with 'shall display' or similar verb f...   \n",
       "\n",
       "                        checks.R9.open_ended_clauses  \\\n",
       "0                                                NaN   \n",
       "1  [The requirement contains an open-ended clause...   \n",
       "2                                                 []   \n",
       "\n",
       "                               checks.R9.explanation  \n",
       "0                                                NaN  \n",
       "1  Specify the minimum percentage of viewers that...  \n",
       "2                                                     \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            original  \\\n",
      "0  If projected the data must be readable. On a 1...   \n",
      "1  If projected the data must be readable. On a 1...   \n",
      "2  If projected the data must be readable.  On a ...   \n",
      "\n",
      "                                    proposed_rewrite  initial_weighted_value  \\\n",
      "0  The data must be readable on a 10x10 projectio...                    0.65   \n",
      "1  A 10x10 projection screen must ensure that at ...                    0.65   \n",
      "2  The system shall ensure that on a 10x-projecti...                    0.65   \n",
      "\n",
      "   weighted_value  \n",
      "0            0.65  \n",
      "1            0.85  \n",
      "2            1.00  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Get pre-revision Accuracy Score\n",
    "final_df = pe.call_evals(final_df, col='original', eval_config=eval_config)\n",
    "final_df = pe.get_failed_evals(final_df)\n",
    "pe.add_weighted_column(final_df, eval_funcs, eval_weights, \"initial_weighted_value\")\n",
    "# Get post-revision Accuracy Score\n",
    "final_df = pe.call_evals(final_df, col='proposed_rewrite', eval_config=eval_config)\n",
    "final_df = pe.get_failed_evals(final_df)\n",
    "pe.add_weighted_column(final_df, eval_funcs, eval_weights, \"weighted_value\")\n",
    "\n",
    "# View original and rewritten requirement statements\n",
    "print(final_df[['original', 'proposed_rewrite', 'initial_weighted_value', 'weighted_value']])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Update of functions below with semaphore to limit concurrent requests\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "import flatdict\n",
    "import time\n",
    "from typing import Any, Dict, List, Optional\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "import pandas as pd\n",
    "import flatdict\n",
    "from pydantic import BaseModel, Field, SecretStr\n",
    "\n",
    "from src import utils\n",
    "from aiswre.components import prompteval as pe\n",
    "from ollama import AsyncClient\n",
    "\n",
    "# Configure retry parameters\n",
    "MAX_RETRIES = 3\n",
    "RETRY_DELAY = 2  # seconds\n",
    "MAX_CONCURRENT_REQUESTS = 5  # Adjust based on your Ollama server capacity\n",
    "\n",
    "async def process_json_responses(\n",
    "    responses, ids, prompt_type, json_key: str = \"requirements_review\"\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Process responses and flatten extracted JSON structures.\"\"\"\n",
    "    processed = []\n",
    "\n",
    "    for i, response in enumerate(responses):\n",
    "        output = {}\n",
    "        \n",
    "        # Extract content from ollama response\n",
    "        if \"message\" in response and \"content\" in response[\"message\"]:\n",
    "            content = response[\"message\"][\"content\"]\n",
    "            try:\n",
    "                response_json = json.loads(content)\n",
    "                if json_key in response_json:\n",
    "                    nested_dicts = response_json[json_key]\n",
    "                    flat_dicts = [flatdict.FlatDict(d, delimiter=\".\") for d in nested_dicts]\n",
    "                    for d in flat_dicts:\n",
    "                        output.update(d)\n",
    "            except (json.JSONDecodeError, TypeError):\n",
    "                output[\"json_parse_error\"] = content\n",
    "        \n",
    "        # Include usage info if available\n",
    "        if \"eval_count\" in response:\n",
    "            output[\"eval_count\"] = response[\"eval_count\"]\n",
    "        if \"prompt_eval_count\" in response:\n",
    "            output[\"prompt_eval_count\"] = response[\"prompt_eval_count\"]\n",
    "        if \"total_duration\" in response:\n",
    "            output[\"total_duration\"] = response[\"total_duration\"]\n",
    "            \n",
    "        output.update(\n",
    "            {\n",
    "                \"requirement_id\": ids[i],\n",
    "                \"prompt_type\": prompt_type,\n",
    "                \"original\": requirements[i] if i < len(requirements) else None,\n",
    "            }\n",
    "        )\n",
    "        processed.append(output)\n",
    "    return processed\n",
    "\n",
    "async def chat_with_retry(ollama_client, model, messages, semaphore, format=\"json\"):\n",
    "    \"\"\"Execute a chat request with retry logic and semaphore for concurrency control.\"\"\"\n",
    "    retries = 0\n",
    "    while retries < MAX_RETRIES:\n",
    "        try:\n",
    "            async with semaphore:  # Limit concurrent connections\n",
    "                return await ollama_client.chat(\n",
    "                    model=model,\n",
    "                    messages=messages,\n",
    "                    format=format\n",
    "                )\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            if retries >= MAX_RETRIES:\n",
    "                print(f\"Failed after {MAX_RETRIES} retries: {str(e)}\")\n",
    "                return {\n",
    "                    \"message\": {\"content\": json.dumps({\"error\": str(e)})},\n",
    "                    \"error\": str(e)\n",
    "                }\n",
    "            print(f\"Retry {retries}/{MAX_RETRIES} after error: {str(e)}\")\n",
    "            await asyncio.sleep(RETRY_DELAY * retries)  # Exponential backoff\n",
    "\n",
    "async def run_requirement_review(\n",
    "    ollama_client,\n",
    "    system_message: str,\n",
    "    user_message: str,\n",
    "    prompt_name: str,\n",
    "    requirements: List[str],\n",
    "    ids: Optional[List[int]] = None,\n",
    "    model: str = \"llama3\",\n",
    "    json_key: str = \"requirements_review\",\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Execute concurrent review prompts and process JSON responses.\"\"\"\n",
    "    if ids is None:\n",
    "        ids = list(range(len(requirements)))\n",
    "    \n",
    "    # Create a semaphore to limit concurrent connections\n",
    "    semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)\n",
    "    \n",
    "    # Build concurrent tasks with semaphore control\n",
    "    tasks = [\n",
    "        chat_with_retry(\n",
    "            ollama_client=ollama_client,\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\",\n",
    "                    \"content\": user_message\n",
    "                    .replace(\"{requirements}\", f\"{req_id}: {req}\")\n",
    "                    .replace(\"{enable_split}\", \"True\"),\n",
    "                },\n",
    "            ],\n",
    "            semaphore=semaphore,\n",
    "            format=\"json\"\n",
    "        )\n",
    "        for req, req_id in zip(requirements, ids)\n",
    "    ]\n",
    "    \n",
    "    # Run all requests concurrently with controlled parallelism\n",
    "    responses = await asyncio.gather(*tasks)\n",
    "\n",
    "    # Process structured JSON responses\n",
    "    return await process_json_responses(responses, ids, prompt_name, json_key)\n",
    "\n",
    "# Batch processing function to handle larger datasets\n",
    "async def process_in_batches(ollama_client, system_message, user_message, prompt_name, \n",
    "                            requirements, batch_size=10, model=\"llama3\", json_key=\"requirements_review\"):\n",
    "    \"\"\"Process requirements in batches to avoid overwhelming the server.\"\"\"\n",
    "    all_results = []\n",
    "    for i in range(0, len(requirements), batch_size):\n",
    "        batch = requirements[i:i+batch_size]\n",
    "        batch_ids = list(range(i, i+len(batch)))\n",
    "        print(f\"Processing batch {i//batch_size + 1}/{(len(requirements)-1)//batch_size + 1} ({len(batch)} items)\")\n",
    "        \n",
    "        batch_results = await run_requirement_review(\n",
    "            ollama_client=ollama_client,\n",
    "            system_message=system_message,\n",
    "            user_message=user_message,\n",
    "            prompt_name=prompt_name,\n",
    "            requirements=batch,\n",
    "            ids=batch_ids,\n",
    "            model=model,\n",
    "            json_key=json_key\n",
    "        )\n",
    "        all_results.extend(batch_results)\n",
    "        \n",
    "        # Add a small delay between batches to let the server breathe\n",
    "        if i + batch_size < len(requirements):\n",
    "            await asyncio.sleep(1)\n",
    "            \n",
    "    return all_results\n",
    "\n",
    "# Instantiate the ollama client and define model\n",
    "DOT_ENV = dotenv_values(\"../.env\")\n",
    "OLLAMA_HOST = DOT_ENV.get('OLLAMA_HOST', 'http://localhost:11434')\n",
    "ollama_client = AsyncClient(host=OLLAMA_HOST)\n",
    "MODEL = 'llama3'  # Use llama3 or another model available in your Ollama instance\n",
    "\n",
    "eval_funcs = [\n",
    "    'eval_avoids_vague_terms',\n",
    "    'eval_definite_articles_usage',\n",
    "    'eval_has_appropriate_subject_verb',\n",
    "    'eval_has_common_units_of_measure',\n",
    "    'eval_has_escape_clauses',\n",
    "    'eval_has_no_open_ended_clauses',\n",
    "    'eval_is_active_voice',\n",
    "]\n",
    "eval_weights = [\n",
    "    0.35,\n",
    "    0.05,\n",
    "    0.15,\n",
    "    0.05,\n",
    "    0.10,\n",
    "    0.10,\n",
    "    0.20\n",
    "]\n",
    "# Make eval config\n",
    "eval_config = pe.make_eval_config(pe, include_funcs=eval_funcs)\n",
    "\n",
    "# Define prompt messages\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a Senior Requirements Quality Analyst and technical editor. \n",
    "You specialize in detecting and fixing requirement defects using authoritative quality rules. \n",
    "Be rigorous, consistent, and concise. Maintain the author's technical intent while removing ambiguity. \n",
    "Do not add new functionality. Ask targeted clarification questions when needed.\n",
    "\n",
    "Response Format (produce exactly this JSON structure):\n",
    "{\n",
    "  \"requirements_review\": [\n",
    "    {\n",
    "      \"requirement_id\": \"<ID>\",\n",
    "      \"original\": \"<original requirement>\",\n",
    "      \"checks\": {\n",
    "        \"R2\": {\"status\": \"pass|fail\", \"active_voice\": [\"<issues>\"], \"explanation\": \"<brief>\"},\n",
    "        \"R3\": {\"status\": \"pass|fail\", \"appropriate_subj_verb\": [\"<issues>\"], \"explanation\": \"<brief>\"},\n",
    "        \"R5\": {\"status\": \"pass|fail\", \"definite_articles\": [\"<issues>\"], \"explanation\": \"<brief>\"},\n",
    "        \"R6\": {\"status\": \"pass|fail\", \"units\": [\"<issues>\"], \"explanation\": \"<brief>\"},\n",
    "        \"R7\": {\"status\": \"pass|fail\", \"vague terms\": [\"<issues>\"], \"explanation\": \"<brief>\"},\n",
    "        \"R8\": {\"status\": \"pass|fail\", \"escape_clauses\": [\"<issues>\"], \"explanation\": \"<brief>\"},\n",
    "        \"R9\": {\"status\": \"pass|fail\", \"open_ended_clauses\": [\"<issues>\"], \"explanation\": \"<brief>\"}\n",
    "      },\n",
    "      \"proposed_rewrite\": \"<single improved requirement that resolves all detected issues>\",\n",
    "      \"split_recommendation\": {\n",
    "        \"needed\": true|false,\n",
    "        \"because\": \"<why>\",\n",
    "        \"split_into\": [\"<Req A>\", \"<Req B>\"]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "Evaluation method:\n",
    "1) Parse inputs and normalize IDs. \n",
    "2) For each requirement, test R2, R3, R5, R6, R7, R8, R9. \n",
    "3) Explain each failure succinctly. \n",
    "4) Rewrite to a single, verifiable sentence unless a split is recommended. \n",
    "5) Apply glossary rules for abbreviations; on first use of allowed abbreviations, prefer the expanded form with abbreviation in parentheses. \n",
    "6) If required numbers are missing and no defaults are provided, use TBD placeholders and ask explicit questions to resolve them. \n",
    "7) Summarize compliance.\n",
    "\n",
    "Important: If {requirements} is empty, respond with a single clarifying question requesting requirements to review and stop.\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT = \"\"\"\n",
    "Task: Review and improve the following requirement statements using the provided variables.\n",
    "\n",
    "Variables:\n",
    "- Requirements (list or newline-separated; may include IDs):\n",
    "  {requirements}\n",
    "- Enable split recommendations (true|false; default true): {enable_split}\n",
    "\n",
    "Produce output strictly in the Response Format JSON. Do not use Markdown.\n",
    "\n",
    "Now perform the review on the provided inputs and return only the Response Format JSON.\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_NAME = 'basic-incose'\n",
    "\n",
    "# Define the requirements to be revised\n",
    "requirements = [\n",
    "    \"If projected the data must be readable.  On a 10x10 projection screen  90% of viewers must be able to read Event / Activity data from a viewing distance of 30\",\n",
    "    \"The product shall ensure that it can only be accessed by authorized users.  The product will be able to distinguish between authorized and unauthorized users in all access attempts\",\n",
    "    \"All business rules specified in the Disputes System shall be in compliance to the guidelines of Regulation E and Regulation Z\",\n",
    "]\n",
    "df = pd.DataFrame({'requirements': requirements})\n",
    "\n",
    "async def main():\n",
    "    # Use batch processing for better control\n",
    "    start_time = time.time()\n",
    "    print(f\"Starting processing of {len(requirements)} requirements...\")\n",
    "    \n",
    "    # For small datasets, you can use run_requirement_review directly\n",
    "    if len(requirements) <= MAX_CONCURRENT_REQUESTS:\n",
    "        revisions = await run_requirement_review(\n",
    "            ollama_client=ollama_client,\n",
    "            system_message=SYSTEM_PROMPT,\n",
    "            user_message=USER_PROMPT,\n",
    "            prompt_name=PROMPT_NAME,\n",
    "            requirements=requirements,\n",
    "            ids=None,\n",
    "            model=MODEL,\n",
    "            json_key=\"requirements_review\"\n",
    "        )\n",
    "    else:\n",
    "        # For larger datasets, use batch processing\n",
    "        revisions = await process_in_batches(\n",
    "            ollama_client=ollama_client,\n",
    "            system_message=SYSTEM_PROMPT,\n",
    "            user_message=USER_PROMPT,\n",
    "            prompt_name=PROMPT_NAME,\n",
    "            requirements=requirements,\n",
    "            batch_size=MAX_CONCURRENT_REQUESTS,\n",
    "            model=MODEL,\n",
    "            json_key=\"requirements_review\"\n",
    "        )\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Processing completed in {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    final_df = pd.DataFrame(revisions)\n",
    "    \n",
    "    # Get post-revision Accuracy Score\n",
    "    final_df = pe.call_evals(final_df, col='proposed_rewrite', eval_config=eval_config)\n",
    "    final_df = pe.get_failed_evals(final_df)\n",
    "    pe.add_weighted_column(final_df, eval_funcs, eval_weights, \"weighted_value\")\n",
    "    \n",
    "    # View original and rewritten requirement statements\n",
    "    print(final_df[['original', 'proposed_rewrite']])\n",
    "    return final_df\n",
    "\n",
    "# Run the async main function\n",
    "final_df = asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# PyQT app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain (/home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain (/home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting PyQt5\n",
      "  Downloading PyQt5-5.15.11-cp38-abi3-manylinux_2_17_x86_64.whl (8.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: ollama in /home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages (0.5.3)\n",
      "Requirement already satisfied: flatdict in /home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages (4.0.1)\n",
      "Collecting PyQt5-Qt5<5.16.0,>=5.15.2\n",
      "  Downloading PyQt5_Qt5-5.15.17-py3-none-manylinux2014_x86_64.whl (61.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting PyQt5-sip<13,>=12.15\n",
      "  Downloading pyqt5_sip-12.17.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.whl (271 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.4/271.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pydantic>=2.9 in /home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages (from ollama) (2.10.6)\n",
      "Requirement already satisfied: httpx>=0.27 in /home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages (from httpx>=0.27->ollama) (1.0.7)\n",
      "Requirement already satisfied: certifi in /home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages (from httpx>=0.27->ollama) (2025.1.31)\n",
      "Requirement already satisfied: anyio in /home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages (from httpx>=0.27->ollama) (4.8.0)\n",
      "Requirement already satisfied: idna in /home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages (from httpx>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages (from pydantic>=2.9->ollama) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages (from pydantic>=2.9->ollama) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages (from anyio->httpx>=0.27->ollama) (1.2.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain (/home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: PyQt5-Qt5, PyQt5-sip, PyQt5\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain (/home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain (/home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain (/home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed PyQt5-5.15.11 PyQt5-Qt5-5.15.17 PyQt5-sip-12.17.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain (/home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain (/home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain (/home/jovyan/shared/renalpa/venv_traceability/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install PyQt5 pandas ollama flatdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "import flatdict\n",
    "from typing import Any, Dict, List, Optional\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from PyQt5.QtWidgets import (QApplication, QMainWindow, QWidget, QVBoxLayout, \n",
    "                            QPushButton, QProgressBar, QLabel, QFileDialog, \n",
    "                            QLineEdit, QHBoxLayout, QMessageBox)\n",
    "from PyQt5.QtCore import Qt, QThread, pyqtSignal, QMimeData\n",
    "from PyQt5.QtGui import QDragEnterEvent, QDropEvent\n",
    "\n",
    "from ollama import AsyncClient\n",
    "\n",
    "class RequirementsProcessorThread(QThread):\n",
    "    progress_updated = pyqtSignal(int, int)\n",
    "    processing_complete = pyqtSignal(pd.DataFrame)\n",
    "    error_occurred = pyqtSignal(str)\n",
    "    \n",
    "    def __init__(self, excel_file, output_dir, model=\"llama3\"):\n",
    "        super().__init__()\n",
    "        self.excel_file = excel_file\n",
    "        self.output_dir = output_dir\n",
    "        self.model = model\n",
    "        \n",
    "    async def process_json_responses(self, responses, ids, prompt_type, json_key=\"requirements_review\"):\n",
    "        \"\"\"Process responses and flatten extracted JSON structures.\"\"\"\n",
    "        processed = []\n",
    "\n",
    "        for i, response in enumerate(responses):\n",
    "            output = {}\n",
    "            \n",
    "            # Extract content from ollama response\n",
    "            if \"message\" in response and \"content\" in response[\"message\"]:\n",
    "                content = response[\"message\"][\"content\"]\n",
    "                try:\n",
    "                    response_json = json.loads(content)\n",
    "                    if json_key in response_json:\n",
    "                        nested_dicts = response_json[json_key]\n",
    "                        flat_dicts = [flatdict.FlatDict(d, delimiter=\".\") for d in nested_dicts]\n",
    "                        for d in flat_dicts:\n",
    "                            output.update(d)\n",
    "                except (json.JSONDecodeError, TypeError):\n",
    "                    output[\"json_parse_error\"] = content\n",
    "            \n",
    "            # Include usage info if available\n",
    "            if \"eval_count\" in response:\n",
    "                output[\"eval_count\"] = response[\"eval_count\"]\n",
    "            if \"prompt_eval_count\" in response:\n",
    "                output[\"prompt_eval_count\"] = response[\"prompt_eval_count\"]\n",
    "            if \"total_duration\" in response:\n",
    "                output[\"total_duration\"] = response[\"total_duration\"]\n",
    "                \n",
    "            output.update(\n",
    "                {\n",
    "                    \"requirement_id\": ids[i],\n",
    "                    \"prompt_type\": prompt_type,\n",
    "                }\n",
    "            )\n",
    "            processed.append(output)\n",
    "        return processed\n",
    "\n",
    "    async def run_requirement_review(self, ollama_client, system_message, user_message, \n",
    "                                    prompt_name, requirements, ids=None, json_key=\"requirements_review\"):\n",
    "        \"\"\"Execute concurrent review prompts and process JSON responses.\"\"\"\n",
    "        if ids is None:\n",
    "            ids = list(range(len(requirements)))\n",
    "        \n",
    "        # Build tasks list\n",
    "        tasks = []\n",
    "        for req, req_id in zip(requirements, ids):\n",
    "            task = ollama_client.chat(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_message},\n",
    "                    {\"role\": \"user\",\n",
    "                        \"content\": user_message\n",
    "                        .replace(\"{requirements}\", f\"{req_id}: {req}\")\n",
    "                        .replace(\"{enable_split}\", \"True\"),\n",
    "                    },\n",
    "                ],\n",
    "                format=\"json\",  # Request JSON format response\n",
    "            )\n",
    "            tasks.append(task)\n",
    "        \n",
    "        # Process requirements one by one with progress updates\n",
    "        responses = []\n",
    "        total = len(tasks)\n",
    "        for i, task in enumerate(tasks):\n",
    "            response = await task\n",
    "            responses.append(response)\n",
    "            self.progress_updated.emit(i + 1, total)\n",
    "        \n",
    "        # Process structured JSON responses\n",
    "        return await self.process_json_responses(responses, ids, prompt_name, json_key)\n",
    "\n",
    "    async def process_requirements(self):\n",
    "        try:\n",
    "            # Load Excel file\n",
    "            df = pd.read_excel(self.excel_file)\n",
    "            \n",
    "            # Extract requirements and IDs\n",
    "            requirements = df['requirement_text'].tolist()\n",
    "            ids = df['requirement_id'].tolist() if 'requirement_id' in df.columns else None\n",
    "            \n",
    "            # Initialize Ollama client\n",
    "            client = AsyncClient()\n",
    "            \n",
    "            # Define system and user messages (these would typically come from a config)\n",
    "            system_message = \"\"\"You are a requirements analysis expert. Analyze the given requirement \n",
    "                              and provide structured feedback in JSON format.\"\"\"\n",
    "            \n",
    "            user_message = \"\"\"Please analyze the following requirement and provide a detailed review:\n",
    "                           {requirements}\n",
    "                           \n",
    "                           Return your analysis in JSON format with the key 'requirements_review' \n",
    "                           containing an array of objects with your findings.\"\"\"\n",
    "            \n",
    "            # Process requirements\n",
    "            results = await self.run_requirement_review(\n",
    "                client, \n",
    "                system_message, \n",
    "                user_message, \n",
    "                \"requirement_review\", \n",
    "                requirements, \n",
    "                ids\n",
    "            )\n",
    "            \n",
    "            # Convert results to DataFrame\n",
    "            results_df = pd.DataFrame(results)\n",
    "            \n",
    "            return results_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error processing requirements: {str(e)}\")\n",
    "\n",
    "    def run(self):\n",
    "        try:\n",
    "            loop = asyncio.new_event_loop()\n",
    "            asyncio.set_event_loop(loop)\n",
    "            results_df = loop.run_until_complete(self.process_requirements())\n",
    "            \n",
    "            # Save results to output directory\n",
    "            output_path = os.path.join(self.output_dir, 'requirements_analysis_results.xlsx')\n",
    "            results_df.to_excel(output_path, index=False)\n",
    "            \n",
    "            self.processing_complete.emit(results_df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.error_occurred.emit(str(e))\n",
    "\n",
    "\n",
    "class DropArea(QWidget):\n",
    "    file_dropped = pyqtSignal(str)\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setAcceptDrops(True)\n",
    "        self.setMinimumSize(400, 200)\n",
    "        \n",
    "        layout = QVBoxLayout()\n",
    "        self.label = QLabel(\"Drop Excel file here\")\n",
    "        self.label.setAlignment(Qt.AlignCenter)\n",
    "        layout.addWidget(self.label)\n",
    "        self.setLayout(layout)\n",
    "        \n",
    "        # Set styling\n",
    "        self.setStyleSheet(\"\"\"\n",
    "            QWidget {\n",
    "                border: 2px dashed #aaa;\n",
    "                border-radius: 5px;\n",
    "                background-color: #f8f8f8;\n",
    "            }\n",
    "            QLabel {\n",
    "                font-size: 16px;\n",
    "                color: #555;\n",
    "            }\n",
    "        \"\"\")\n",
    "        \n",
    "    def dragEnterEvent(self, event: QDragEnterEvent):\n",
    "        if event.mimeData().hasUrls() and event.mimeData().urls()[0].toLocalFile().endswith(('.xlsx', '.xls')):\n",
    "            event.acceptProposedAction()\n",
    "            self.setStyleSheet(\"\"\"\n",
    "                QWidget {\n",
    "                    border: 2px dashed #3498db;\n",
    "                    border-radius: 5px;\n",
    "                    background-color: #e8f4fc;\n",
    "                }\n",
    "                QLabel {\n",
    "                    font-size: 16px;\n",
    "                    color: #3498db;\n",
    "                }\n",
    "            \"\"\")\n",
    "        \n",
    "    def dragLeaveEvent(self, event):\n",
    "        self.setStyleSheet(\"\"\"\n",
    "            QWidget {\n",
    "                border: 2px dashed #aaa;\n",
    "                border-radius: 5px;\n",
    "                background-color: #f8f8f8;\n",
    "            }\n",
    "            QLabel {\n",
    "                font-size: 16px;\n",
    "                color: #555;\n",
    "            }\n",
    "        \"\"\")\n",
    "        \n",
    "    def dropEvent(self, event: QDropEvent):\n",
    "        file_path = event.mimeData().urls()[0].toLocalFile()\n",
    "        self.label.setText(f\"File: {os.path.basename(file_path)}\")\n",
    "        self.file_dropped.emit(file_path)\n",
    "        self.setStyleSheet(\"\"\"\n",
    "            QWidget {\n",
    "                border: 2px solid #2ecc71;\n",
    "                border-radius: 5px;\n",
    "                background-color: #eafaf1;\n",
    "            }\n",
    "            QLabel {\n",
    "                font-size: 16px;\n",
    "                color: #2ecc71;\n",
    "            }\n",
    "        \"\"\")\n",
    "\n",
    "\n",
    "class MainWindow(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setWindowTitle(\"Requirements Analyzer\")\n",
    "        self.setMinimumSize(600, 400)\n",
    "        \n",
    "        self.excel_file_path = None\n",
    "        self.output_dir = os.path.expanduser(\"~/Documents\")\n",
    "        \n",
    "        self.init_ui()\n",
    "        \n",
    "    def init_ui(self):\n",
    "        central_widget = QWidget()\n",
    "        main_layout = QVBoxLayout(central_widget)\n",
    "        \n",
    "        # Drop area for Excel file\n",
    "        self.drop_area = DropArea()\n",
    "        self.drop_area.file_dropped.connect(self.set_excel_file)\n",
    "        main_layout.addWidget(self.drop_area)\n",
    "        \n",
    "        # Output directory selection\n",
    "        dir_layout = QHBoxLayout()\n",
    "        dir_layout.addWidget(QLabel(\"Output Directory:\"))\n",
    "        \n",
    "        self.output_dir_edit = QLineEdit(self.output_dir)\n",
    "        dir_layout.addWidget(self.output_dir_edit)\n",
    "        \n",
    "        browse_btn = QPushButton(\"Browse...\")\n",
    "        browse_btn.clicked.connect(self.browse_output_dir)\n",
    "        dir_layout.addWidget(browse_btn)\n",
    "        \n",
    "        main_layout.addLayout(dir_layout)\n",
    "        \n",
    "        # Model selection\n",
    "        model_layout = QHBoxLayout()\n",
    "        model_layout.addWidget(QLabel(\"Model:\"))\n",
    "        \n",
    "        self.model_edit = QLineEdit(\"llama3\")\n",
    "        model_layout.addWidget(self.model_edit)\n",
    "        \n",
    "        main_layout.addLayout(model_layout)\n",
    "        \n",
    "        # Progress bar\n",
    "        self.progress_bar = QProgressBar()\n",
    "        self.progress_bar.setRange(0, 100)\n",
    "        self.progress_bar.setValue(0)\n",
    "        main_layout.addWidget(self.progress_bar)\n",
    "        \n",
    "        # Status label\n",
    "        self.status_label = QLabel(\"Ready\")\n",
    "        self.status_label.setAlignment(Qt.AlignCenter)\n",
    "        main_layout.addWidget(self.status_label)\n",
    "        \n",
    "        # Run button\n",
    "        self.run_button = QPushButton(\"Run Analysis\")\n",
    "        self.run_button.clicked.connect(self.run_analysis)\n",
    "        self.run_button.setEnabled(False)\n",
    "        main_layout.addWidget(self.run_button)\n",
    "        \n",
    "        self.setCentralWidget(central_widget)\n",
    "        \n",
    "    def set_excel_file(self, file_path):\n",
    "        self.excel_file_path = file_path\n",
    "        self.run_button.setEnabled(True)\n",
    "        self.status_label.setText(f\"Ready to analyze: {os.path.basename(file_path)}\")\n",
    "        \n",
    "    def browse_output_dir(self):\n",
    "        dir_path = QFileDialog.getExistingDirectory(\n",
    "            self, \"Select Output Directory\", self.output_dir\n",
    "        )\n",
    "        if dir_path:\n",
    "            self.output_dir = dir_path\n",
    "            self.output_dir_edit.setText(dir_path)\n",
    "            \n",
    "    def run_analysis(self):\n",
    "        if not self.excel_file_path:\n",
    "            QMessageBox.warning(self, \"Error\", \"Please select an Excel file first.\")\n",
    "            return\n",
    "            \n",
    "        output_dir = self.output_dir_edit.text()\n",
    "        if not os.path.isdir(output_dir):\n",
    "            QMessageBox.warning(self, \"Error\", \"Please select a valid output directory.\")\n",
    "            return\n",
    "            \n",
    "        model = self.model_edit.text().strip()\n",
    "        if not model:\n",
    "            QMessageBox.warning(self, \"Error\", \"Please specify a model name.\")\n",
    "            return\n",
    "            \n",
    "        # Disable UI elements during processing\n",
    "        self.run_button.setEnabled(False)\n",
    "        self.status_label.setText(\"Processing requirements...\")\n",
    "        \n",
    "        # Start processing thread\n",
    "        self.processor_thread = RequirementsProcessorThread(\n",
    "            self.excel_file_path, output_dir, model\n",
    "        )\n",
    "        self.processor_thread.progress_updated.connect(self.update_progress)\n",
    "        self.processor_thread.processing_complete.connect(self.processing_finished)\n",
    "        self.processor_thread.error_occurred.connect(self.processing_error)\n",
    "        self.processor_thread.start()\n",
    "        \n",
    "    def update_progress(self, current, total):\n",
    "        percentage = int((current / total) * 100)\n",
    "        self.progress_bar.setValue(percentage)\n",
    "        self.status_label.setText(f\"Processing requirement {current} of {total}...\")\n",
    "        \n",
    "    def processing_finished(self, results_df):\n",
    "        output_path = os.path.join(self.output_dir_edit.text(), 'requirements_analysis_results.xlsx')\n",
    "        self.status_label.setText(f\"Analysis complete! Results saved to: {output_path}\")\n",
    "        self.progress_bar.setValue(100)\n",
    "        self.run_button.setEnabled(True)\n",
    "        \n",
    "        QMessageBox.information(\n",
    "            self, \n",
    "            \"Processing Complete\", \n",
    "            f\"Requirements analysis complete!\\n\\nResults saved to:\\n{output_path}\"\n",
    "        )\n",
    "        \n",
    "    def processing_error(self, error_message):\n",
    "        self.status_label.setText(f\"Error: {error_message}\")\n",
    "        self.progress_bar.setValue(0)\n",
    "        self.run_button.setEnabled(True)\n",
    "        \n",
    "        QMessageBox.critical(\n",
    "            self,\n",
    "            \"Processing Error\",\n",
    "            f\"An error occurred during processing:\\n\\n{error_message}\"\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    window = MainWindow()\n",
    "    window.show()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_traceability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
