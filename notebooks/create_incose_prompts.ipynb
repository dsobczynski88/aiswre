{
 "cells": [
  {
   "cell_type": "raw",
   "id": "707938e5",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "The goal of this notebook is to create prompts to support a requirement reviewer application using a standard body of work (INCOSE Guide to Writing Requirements).\n",
    "\n",
    "Specifically, the goal is to create a prompt for each high-level attribute group, as described in Section 4 of the INCOSE Guide. \n",
    "\n",
    "For each high-level attribute group, there may exist several different rules. Each defined rule contains a defintion, elaboration, examples, and possibly exceptions. \n",
    "\n",
    "The resulting prompt for each attribute group should take into account all the context provided for that rule and summarize it effectively into a single prompt designed to review and revise requirements to better align with the criteria described in the rules for that attribute group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec629719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional, Literal, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a725c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load configuration\n",
    "from dotenv import dotenv_values\n",
    "from src import utils\n",
    "\n",
    "# Load config settings\n",
    "DOT_ENV = dotenv_values(\"../.env\")\n",
    "config = utils.load_config(\"../config.yaml\")\n",
    "\n",
    "# Create a unique run-id folder to store outputs\n",
    "config[\"FILE_LOCATIONS\"][\"MAIN_DATA_FOLDER\"] = \"../src/data\"\n",
    "output_directory = utils.make_output_directory(config[\"FILE_LOCATIONS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce529fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: Preprocess the guide\n",
    "from pathlib import Path\n",
    "from src.components import incose\n",
    "incose_df = incose.preprocess_incose_guide(\n",
    "            input_path=Path(config['FILE_LOCATIONS']['INCOSE_GUIDE']),\n",
    "            output_path=Path(output_directory),\n",
    "            start_page=65,\n",
    "            end_page=115,\n",
    "            regex=config['INCOSE_GUIDE_SETTINGS']['SECTIONS_REGEX_PAT'],\n",
    "            replace_tokens=config['INCOSE_GUIDE_SETTINGS']['REPLACE_TOKENS'],\n",
    "            subpatterns=config['INCOSE_GUIDE_SETTINGS']['SUBPATTERNS'],\n",
    "            replace_with=config['INCOSE_GUIDE_SETTINGS']['REPLACE_WITH']\n",
    "        )\n",
    "incose_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be04f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2: Group all rule context based on which attribute group (e.g., accuracy, concision)\n",
    "from src.components import prompteval as pe\n",
    "rule_group_config = pe.make_rule_group_config(pe, config['SECTION_4_RULE_GROUPS'])\n",
    "incose_df['rule_group'] = incose_df['rule_number'].map(rule_group_config)\n",
    "print(set(incose_df['rule_group'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c1a97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## View the accuracy rule group slice of the incose_df\n",
    "incose_df_accuracy = incose_df.loc[incose_df['rule_group'] == 'Accuracy']\n",
    "context_str = ''\n",
    "for index, row in incose_df_accuracy.iterrows():\n",
    "    context_str += f\"\"\"\n",
    "    {row['rule_number']}: {row['rule_title']} \n",
    "    Definition: {row['definition']}\n",
    "    Elaboration: {row['elaboration']}\n",
    "    Examples: {row['examples']}\n",
    "    \"\"\"\n",
    "\n",
    "print(context_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3871cc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# context str for pre-warming prompt\n",
    "context_str = \"\"\"\n",
    "Here’s a practical, lightweight way to review a requirement for accuracy, aligned with the INCOSE Guide’s Section 4 rules and quality characteristics.\n",
    "\n",
    "Preparation (what to have in hand)\n",
    "- Source: stakeholder need, parent requirement, contract/standard, hazard/mission need.\n",
    "- Context: operational scenarios/modes, interface definitions, architecture or allocation, performance budgets, environmental ranges.\n",
    "- Verification approach: intended method (Test/Analysis/Inspection/Demonstration) and acceptance criteria.\n",
    "\n",
    "Three-pass review method\n",
    "\n",
    "Pass 1 — Language and structure (quick screen)\n",
    "- Subject and shall: Does the statement name the item (e.g., “The system”) and use “shall” for the requirement?\n",
    "- One per requirement: Is there only one enforceable statement (no and/or, chained clauses)?\n",
    "- Positive, active, clear: Prefer positive statements with explicit trigger/condition (“When/If…”).\n",
    "- Measurable: Are there concrete, measurable criteria with units, tolerances, and time bounds?\n",
    "- Unambiguous wording: No vague terms (robust, user-friendly, minimize, as necessary), no open-ended “etc.” or “including but not limited to,” no undefined acronyms.\n",
    "\n",
    "Pass 2 — Technical correctness and completeness (accuracy)\n",
    "- Trace and necessity: Is it traceable to a valid source/parent? Is it actually needed at this level?\n",
    "- Right level of abstraction: States “what” for this level (no premature design), or, if it must constrain design, is the rationale clear and approved?\n",
    "- Context and conditions: Are operating modes, environmental conditions, and preconditions explicit (temp, voltage, state, load, network conditions)?\n",
    "- Values and units sanity check:\n",
    "  - Threshold vs. objective correct? Direction correct (min/max/<=/>=)?\n",
    "  - Units consistent with parent budgets and interfaces; conversions checked.\n",
    "  - Significant figures and tolerances realistic and testable.\n",
    "- Alignment with allocations/budgets: Do numbers roll down correctly from parent performance budgets and constraints? Any double-counting or gaps?\n",
    "- Feasibility: Technically achievable with current technology and margins; compatible with schedule/cost/risk.\n",
    "- Interfaces precise: External items named with version/ID; data types, ranges, and protocols defined or referenced precisely.\n",
    "- Standards/references: Cited by exact identifier and revision; referenced clauses match the intended behavior.\n",
    "- Exceptions/faults: Does it define behavior under relevant faults or edge cases, or is there a linked requirement that does?\n",
    "\n",
    "Pass 3 — Verifiability and conflict checks\n",
    "- Pass/fail interpretation: Can a tester decide unambiguously if it passes? Sketch a test or analysis in one or two sentences.\n",
    "- Verification method fit: Chosen method (T/A/I/D) is appropriate and feasible; required facilities/instruments exist.\n",
    "- Boundary tests: Identify boundary values and worst-case conditions; ensure requirement can be verified there.\n",
    "- Consistency: No conflict with peer requirements (same set and interfacing items); terminology and units consistent.\n",
    "- Redundancy: Not duplicating another requirement; if similar, ensure they don’t diverge or contradict.\n",
    "- TBD/TBR control: Any placeholders have owners, due dates, and resolution criteria.\n",
    "\n",
    "Quick checklist you can apply to any single requirement\n",
    "1) Who is the subject? (“The [item] shall …”)\n",
    "2) Under what condition/mode? (“When/If/While …”)\n",
    "3) What outcome/result is required? (state the “what,” not the “how”)\n",
    "4) How much/how well, with units/tolerances/time bounds?\n",
    "5) Where did this come from? (trace to source/parent; is it necessary?)\n",
    "6) Is it feasible with current budgets/architecture?\n",
    "7) Are interfaces/standards referenced precisely (name, ID, version)?\n",
    "8) Is the wording free of ambiguity and open-ended terms?\n",
    "9) What is the verification method, and what would the pass/fail test look like?\n",
    "10) Any conflicts or duplicates with other requirements?\n",
    "\n",
    "Simple accuracy aids\n",
    "- Paraphrase test: Have two reviewers independently restate the requirement in their own words; differences reveal ambiguity/errors.\n",
    "- EARS reframe: Restate as “When <trigger>, the <item> shall <response> within <time/criteria>” to expose missing conditions or measures.\n",
    "- Boundary walkthrough: Check extremes of environment/inputs for hidden constraints.\n",
    "- Unit/number sanity check: Recalculate conversions; compare to known performance and parent allocations.\n",
    "- Adversarial read: Ask, “Could this be satisfied in an unintended way?” If yes, tighten it.\n",
    "\n",
    "Example (condensed)\n",
    "Original: “The controller shall save data quickly during power loss.”\n",
    "Review outcome:\n",
    "- Add subject/measure/condition: “When input voltage drops below 10.0 V for more than 2 ms, the controller shall commit the current configuration to non-volatile memory within 100 ms without data corruption.”\n",
    "- Check accuracy: 10.0 V/2 ms threshold matches power budget and hold-up time; 100 ms aligns with memory write time plus margin; “data corruption” defined elsewhere; verification by test with controlled brownout; no conflicts with shutdown sequence requirement.\n",
    "\n",
    "Deliverables from the review\n",
    "- Marked-up requirement (or rewritten version)\n",
    "- Recorded findings: defects, questions, TBDs, conflicts\n",
    "- Proposed verification method and sketch of acceptance\n",
    "- Traceability updates (source link, parent allocation)\n",
    "- Decision: accept, revise, split, or defer with TBR/TBD controls\n",
    "\n",
    "If you share a few of your requirements, I can run this review method on them and show the before/after along with the specific issues found.\n",
    "\n",
    "Use the following JSON response format in the prompt:\n",
    "\n",
    "{\n",
    "  \"requirements_review\": [\n",
    "    {\n",
    "      \"requirement_id\": \"<ID>\",\n",
    "      \"original\": \"<original requirement>\",\n",
    "      \"checks\": {\n",
    "        \"<rule_id>\": {\"status\": \"pass|fail\", \"<rule description>\": [\"<issues>\"], \"explanation\": \"<brief>\"},\n",
    "      },\n",
    "      \"proposed_rewrite\": \"<single improved requirement that resolves all detected issues>\",\n",
    "      \"split_recommendation\": {\n",
    "        \"needed\": true|false,\n",
    "        \"because\": \"<why>\",\n",
    "        \"split_into\": [\"<Req A>\", \"<Req B>\"]\n",
    "      },\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5dcfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3: Generate a prompt for each attribute group\n",
    "from pydantic import BaseModel, SecretStr, Field\n",
    "from openai import OpenAI\n",
    "import src\n",
    "from src.components.promptrunner import ResponseClient\n",
    "\n",
    "openai_api_key = str(DOT_ENV['OPENAI_API_KEY'])\n",
    "openai_api_key_secret = SecretStr(openai_api_key)\n",
    "# Create OpenAI instance\n",
    "client = OpenAI(\n",
    "    # Replace with your actual API key or use: api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=openai_api_key_secret.get_secret_value()\n",
    ")\n",
    "resp_client = ResponseClient(client=client, model=\"gpt-5\")\n",
    "# Create a prompt using this formatted checklist\n",
    "class PromptTemplate(BaseModel):\n",
    "    system: str = Field(description=\"A prompt system message\") \n",
    "    user: str = Field(description=\"A user message\")\n",
    "\n",
    "system_message = \"\"\"\n",
    "You're a world-leading expert in AI prompt engineering.\n",
    "You will be given a description of a task and your job is to create a prompt template to automate that task using prompt engineering best practices.\n",
    "\n",
    "Prompt engineering is the process of discovering prompts which reliably yield useful or desired results.\n",
    "Prompt Engineering best practices include:\n",
    "1. Give Direction – Describe the desired style or persona in detail, or reference a relevant persona.\n",
    "2. Specify Format – Define what rules to follow, and the required structure of the response.\n",
    "3. Provide Examples – Insert a diverse set of test cases where the task was done correctly.\n",
    "\n",
    "Your prompt template must take context from the user in the form of relevant input variables surrounded by curly brackets i.e. {{input_variable}}. These placeholders should be labelled in the template as they will be replaced with values when the prompt is used. Your prompt should provide multiple examples of different values the input variables might take, and what the expected responses would be in these test cases.\n",
    "\n",
    "Respond only with your prompt template, and nothing else. Be creative.\n",
    "\n",
    "DO NOT USE EMOJIS\n",
    "\"\"\"\n",
    "\n",
    "user_message = f\"\"\"\n",
    "Here is the task:\n",
    "Generate reviews of requirements according to the provided Context.\n",
    "\n",
    "Context\n",
    "---\n",
    "{context_str}\n",
    "\n",
    "Rules\n",
    "---\n",
    "The prompt will be deemed successful if it matches the following criteria:\n",
    "- Is the submission helpful, insightful, and appropriate?\n",
    "- Are prompt engineering best practices being used?\n",
    "- Relevant input variables are included in the prompt template\n",
    "\n",
    "PROMPT TEMPLATE:\n",
    "\"\"\"\n",
    "\n",
    "print(f\"System:\\n {system_message}\")\n",
    "\n",
    "print(f\"User:\\n {user_message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7724cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run prompt\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_message}\n",
    "]\n",
    "structured_response = resp_client.get_structured_response(\n",
    "    messages=messages,\n",
    "    response_format=PromptTemplate,\n",
    ")\n",
    "resp_client.check_structured_output(structured_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e926cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an INCOSE-trained senior systems engineer and requirements quality reviewer. Your mission is to review each provided requirement for accuracy and quality using a disciplined three-pass method and produce only the requested JSON output. Be precise, neutral, and actionable. Do not include extra commentary outside the JSON. If information is missing, flag it explicitly and proceed conservatively. Prefer EARS-style phrasing when proposing rewrites. Ensure all units, tolerances, and time bounds are explicit and testable. Obey the provided context and verification constraints. If a requirement contains multiple enforceable statements, recommend a split and propose the decomposed requirements.\n"
     ]
    }
   ],
   "source": [
    "print(structured_response.parsed.system)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28a75d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task\n",
      "Review each requirement using the provided review context and produce a structured JSON evaluation with checks, a concise improved rewrite, and a split recommendation when applicable.\n",
      "\n",
      "Follow this method (aligned to the supplied review context):\n",
      "- Pass 1 — Language and structure\n",
      "- Pass 2 — Technical correctness and completeness (accuracy)\n",
      "- Pass 3 — Verifiability and conflict checks\n",
      "\n",
      "Rule IDs and descriptions to use for checks\n",
      "- L1: Subject and shall — Names the item and uses “shall”.\n",
      "- L2: One per requirement — Only one enforceable statement; avoids and/or, chained clauses.\n",
      "- L3: Positive, active, clear — Prefer positive active voice with explicit trigger/condition.\n",
      "- L4: Measurable — Concrete, measurable criteria with units, tolerances, time bounds.\n",
      "- L5: Unambiguous wording — No vague terms or open-ended phrases; acronyms defined.\n",
      "- T1: Trace and necessity — Traceable to valid source/parent; needed at this level.\n",
      "- T2: Right level of abstraction — States the “what”; design constraints justified if present.\n",
      "- T3: Context and conditions — Modes, environments, preconditions explicit.\n",
      "- T4: Values and units sanity — Threshold vs. objective, direction, units, sig figs, tolerances.\n",
      "- T5: Alignment with allocations/budgets — Numbers roll down; no double-counting or gaps.\n",
      "- T6: Feasibility — Technically achievable within schedule/cost/risk and margins.\n",
      "- T7: Interfaces precise — External items named with version/ID; data types/ranges/protocols precise.\n",
      "- T8: Standards/references — Cited by exact identifier/revision; clauses match intent.\n",
      "- T9: Exceptions/faults — Defines behavior under faults/edges or links to such requirements.\n",
      "- V1: Pass/fail interpretation — Unambiguous pass/fail; sketch test/analysis.\n",
      "- V2: Verification method fit — Chosen T/A/I/D appropriate and feasible.\n",
      "- V3: Boundary tests — Identifies boundary values/worst-case and verifiability there.\n",
      "- V4: Consistency — No conflicts with peer requirements; terminology/units consistent.\n",
      "- V5: Redundancy — Not duplicative; no divergence or contradiction.\n",
      "- V6: TBD/TBR control — Placeholders tracked with owners/dates/criteria.\n",
      "\n",
      "Output format (return only this JSON):\n",
      "{\n",
      "  \"requirements_review\": [\n",
      "    {\n",
      "      \"requirement_id\": \"<ID>\",\n",
      "      \"original\": \"<original requirement>\",\n",
      "      \"checks\": {\n",
      "        \"<rule_id>\": {\"status\": \"pass|fail\", \"<rule description>\": [\"<issues or notes>\"], \"explanation\": \"<brief rationale>\"}\n",
      "      },\n",
      "      \"proposed_rewrite\": \"<single improved requirement that resolves detected issues; use EARS style where helpful>\",\n",
      "      \"split_recommendation\": {\n",
      "        \"needed\": true|false,\n",
      "        \"because\": \"<why>\",\n",
      "        \"split_into\": [\"<Req A>\", \"<Req B>\"]\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Input variables (fill in the placeholders exactly as {{variable}} when using this template)\n",
      "- {{project_name}}: Name of the project/system.\n",
      "- {{output_language}}: Language for the output text (default: English).\n",
      "- {{review_context}}: Authoritative review guidance text (e.g., INCOSE-based context provided).\n",
      "- {{requirements}}: List of requirements to review. Each requirement may have fields id and text. If no id, assign using {{id_prefix}}-NNN.\n",
      "- {{sources}}: Traceability sources (stakeholder needs, parent requirements, contracts/standards, hazards/missions) with IDs.\n",
      "- {{operational_context}}: Operating modes, scenarios, environments, states.\n",
      "- {{interfaces}}: Interface definitions, external items with names and version/IDs.\n",
      "- {{architecture_allocation}}: Allocation, constraints, and applicable performance budgets.\n",
      "- {{performance_budgets}}: Quantified budgets/allocations to check values against.\n",
      "- {{verification_plan}}: Intended verification methods (Test/Analysis/Inspection/Demonstration) and acceptance criteria by requirement or topic.\n",
      "- {{standards}}: Cited standards/specs with identifiers and revisions.\n",
      "- {{glossary}}: Defined terms and acronyms.\n",
      "- {{peer_requirements}}: Neighbor/peer requirements for conflict/duplication checks.\n",
      "- {{constraints}}: Known design constraints and rationales.\n",
      "- {{assumptions}}: Allowed assumptions if data is missing.\n",
      "- {{strictness_level}}: lenient | normal | strict.\n",
      "- {{unit_system}}: SI | Imperial | Mixed (how to present units if rewriting).\n",
      "- {{id_prefix}}: Prefix to assign new IDs (e.g., REQ).\n",
      "- {{max_rewrites}}: Max number of alternative rewrites to consider; still return only one in proposed_rewrite.\n",
      "\n",
      "Instructions\n",
      "1) Read {{review_context}} and use it as the governing guide. Apply the three-pass method and the quick checklist.\n",
      "2) For each item in {{requirements}}:\n",
      "   - Use its existing ID or assign {{id_prefix}}-###.\n",
      "   - Populate every rule from L1 through V6 with a pass/fail and brief explanations. If information is insufficient, choose fail and list what is missing, unless {{strictness_level}} is lenient, in which case note \"insufficient information\" in issues and make a conservative pass/fail judgment.\n",
      "   - Where appropriate, sketch a one- or two-sentence verification concept in V1 or V2 explanations.\n",
      "   - In proposed_rewrite, produce one improved, testable requirement that addresses all identified defects where possible. Use EARS form: \"When <trigger>, the <item> shall <response> <within/by> <time/criteria> <under conditions>.\"\n",
      "   - If the original requirement contains multiple enforceable statements, recommend split_recommendation.needed = true and propose split_into as distinct, self-contained requirements. If split is needed, proposed_rewrite should still provide one of the resulting clear requirements (typically the primary one).\n",
      "3) Keep all numbers consistent with {{performance_budgets}}, {{interfaces}}, and {{standards}}. If a value is missing, propose a bounded, testable value only if justified by {{assumptions}}; otherwise mark as TBD and fail L4/V1/V3 with explanation.\n",
      "4) Use {{output_language}} for all narrative text.\n",
      "5) Return only the JSON object specified above, no extra text.\n",
      "\n",
      "Examples (illustrative)\n",
      "\n",
      "Example 1 — Minimal vague requirement improved using provided budgets\n",
      "Input\n",
      "- {{project_name}}: Orion-UAV Flight Controller\n",
      "- {{output_language}}: English\n",
      "- {{review_context}}: INCOSE-style guidance as provided\n",
      "- {{requirements}}: [{\"id\":\"REQ-12\",\"text\":\"The controller shall save data quickly during power loss.\"}]\n",
      "- {{sources}}: {\"parent\":\"PR-5 Prevent configuration loss during brownouts\",\"hazard\":\"HAZ-003 Power integrity\"}\n",
      "- {{operational_context}}: {\"modes\":[\"Normal\",\"Shutdown\"],\"environment\":{\"voltage\":{\"nominal\":12.0,\"brownout\":10.0},\"hold_up_ms\":4}}\n",
      "- {{performance_budgets}}: {\"nv_write_time_ms\":70,\"hold_up_margin_ms\":2,\"brownout_threshold_V\":10.0}\n",
      "- {{verification_plan}}: {\"REQ-12\":\"Test using programmable supply to induce brownout; inspect NVM contents\"}\n",
      "- {{interfaces}}: {}\n",
      "- {{standards}}: {}\n",
      "- {{glossary}}: {\"data corruption\":\"Mismatch vs CRC-32 check of stored configuration\"}\n",
      "- {{peer_requirements}}: []\n",
      "- {{constraints}}: {}\n",
      "- {{assumptions}}: {\"commit_scope\":\"current configuration only\"}\n",
      "- {{strictness_level}}: normal\n",
      "- {{unit_system}}: SI\n",
      "- {{id_prefix}}: REQ\n",
      "- {{max_rewrites}}: 1\n",
      "\n",
      "Expected output\n",
      "{\n",
      "  \"requirements_review\": [\n",
      "    {\n",
      "      \"requirement_id\": \"REQ-12\",\n",
      "      \"original\": \"The controller shall save data quickly during power loss.\",\n",
      "      \"checks\": {\n",
      "        \"L1\": {\"status\":\"pass\",\"Subject and shall — Names the item and uses ‘shall’.\":[\"Subject ‘The controller’ present; uses ‘shall’\"],\"explanation\":\"Grammatically correct subject and modal verb.\"},\n",
      "        \"L2\": {\"status\":\"pass\",\"One per requirement — Only one enforceable statement.\":[\"Single action: save data\"],\"explanation\":\"No and/or or chained clauses.\"},\n",
      "        \"L3\": {\"status\":\"fail\",\"Positive, active, clear — Explicit trigger/condition.\":[\"Missing explicit trigger for power loss\"],\"explanation\":\"No condition threshold/time specified for brownout.\"},\n",
      "        \"L4\": {\"status\":\"fail\",\"Measurable — Concrete criteria with units/tolerances/time.\":[\"‘quickly’ is not measurable\"],\"explanation\":\"No time bound or integrity criterion.\"},\n",
      "        \"L5\": {\"status\":\"fail\",\"Unambiguous wording — No vague terms/open-ended phrases.\":[\"Vague term: ‘quickly’\"],\"explanation\":\"Ambiguity prevents objective verification.\"},\n",
      "        \"T1\": {\"status\":\"pass\",\"Trace and necessity — Valid source/parent.\":[\"Traces to PR-5 and HAZ-003\"],\"explanation\":\"Requirement is necessary to mitigate brownout hazard.\"},\n",
      "        \"T2\": {\"status\":\"pass\",\"Right level of abstraction — States the ‘what’.\":[\"Specifies outcome, not implementation\"],\"explanation\":\"No premature design in the original.\"},\n",
      "        \"T3\": {\"status\":\"fail\",\"Context and conditions — Modes/environments explicit.\":[\"No voltage threshold or duration\"],\"explanation\":\"Operating condition for brownout not defined.\"},\n",
      "        \"T4\": {\"status\":\"fail\",\"Values and units sanity — Direction/units/sig figs.\":[\"No values to sanity-check\"],\"explanation\":\"Cannot verify direction or units without thresholds.\"},\n",
      "        \"T5\": {\"status\":\"fail\",\"Alignment with allocations/budgets — Roll-down correct.\":[\"No numbers to compare to budgets\"],\"explanation\":\"Add time bound consistent with nv_write_time and hold-up.\"},\n",
      "        \"T6\": {\"status\":\"pass\",\"Feasibility — Achievable within margins.\":[\"Feasible if ≤100 ms given budgets\"],\"explanation\":\"Based on nv_write_time 70 ms plus 30 ms margin.\"},\n",
      "        \"T7\": {\"status\":\"pass\",\"Interfaces precise — External items versioned.\":[\"No external interface referenced\"],\"explanation\":\"Not applicable; no interface in scope.\"},\n",
      "        \"T8\": {\"status\":\"pass\",\"Standards/references — Exact identifier/revision.\":[\"No standard cited\"],\"explanation\":\"None required for this behavior.\"},\n",
      "        \"T9\": {\"status\":\"fail\",\"Exceptions/faults — Behavior under faults/edges.\":[\"No explicit handling under brownout\"],\"explanation\":\"Condition and fault mode not formalized.\"},\n",
      "        \"V1\": {\"status\":\"fail\",\"Pass/fail interpretation — Unambiguous decision.\":[\"Tester cannot determine pass/fail without thresholds\"],\"explanation\":\"Define voltage/time and integrity criteria.\"},\n",
      "        \"V2\": {\"status\":\"pass\",\"Verification method fit — T/A/I/D appropriate.\":[\"Test via controlled brownout\"],\"explanation\":\"Programmable supply and CRC inspection feasible.\"},\n",
      "        \"V3\": {\"status\":\"fail\",\"Boundary tests — Worst-case/boundaries verifiable.\":[\"No boundary values specified\"],\"explanation\":\"Need threshold 10.0 V and duration 2 ms for boundary testing.\"},\n",
      "        \"V4\": {\"status\":\"pass\",\"Consistency — No conflicts with peers.\":[\"No peers provided\"],\"explanation\":\"No conflicts identified with provided set.\"},\n",
      "        \"V5\": {\"status\":\"pass\",\"Redundancy — Not duplicative.\":[\"Unique within provided set\"],\"explanation\":\"No duplicate detected.\"},\n",
      "        \"V6\": {\"status\":\"pass\",\"TBD/TBR control — Placeholders managed.\":[\"No TBD/TBR tokens present\"],\"explanation\":\"N/A.\"}\n",
      "      },\n",
      "      \"proposed_rewrite\": \"When input voltage drops below 10.0 V for more than 2 ms, the controller shall commit the current configuration to non-volatile memory within 100 ms without data corruption.\",\n",
      "      \"split_recommendation\": {\"needed\": false, \"because\": \"Single enforceable statement after rewrite.\", \"split_into\": []}\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Example 2 — Design-constraining requirement reframed to performance\n",
      "Input\n",
      "- {{project_name}}: Atlas-AGV Navigation Computer\n",
      "- {{output_language}}: English\n",
      "- {{review_context}}: INCOSE-style guidance as provided\n",
      "- {{requirements}}: [{\"id\":\"SYS-NAV-021\",\"text\":\"The system shall use a Quad-Core ARM Cortex-A72 processor running at 2.0 GHz to ensure fast response.\"}]\n",
      "- {{sources}}: {\"stakeholder\":\"STK-12 Fast teleop response\",\"parent\":\"PRF-02 Control loop latency\"}\n",
      "- {{operational_context}}: {\"modes\":[\"Teleop\",\"Autonomy\"],\"environment\":{\"temp_C\":[-10,55]}}\n",
      "- {{performance_budgets}}: {\"teleop_e2e_latency_ms\":80,\"control_loop_rate_Hz\":200,\"cpu_util_max_pct\":80}\n",
      "- {{verification_plan}}: {\"PRF-02\":\"Test end-to-end latency with HIL rig\"}\n",
      "- {{interfaces}}: {\"sensors\":[\"IMU IF-IMU-1 v2.1\"],\"actuators\":[\"Drive IF-DRV-3 v1.4\"]}\n",
      "- {{standards}}: {}\n",
      "- {{glossary}}: {}\n",
      "- {{peer_requirements}}: [\"SYS-NAV-020 The system shall support 200 Hz stabilization loop.\"]\n",
      "- {{constraints}}: {}\n",
      "- {{assumptions}}: {\"design_choice_allowed\":false}\n",
      "- {{strictness_level}}: strict\n",
      "- {{unit_system}}: SI\n",
      "- {{id_prefix}}: REQ\n",
      "- {{max_rewrites}}: 1\n",
      "\n",
      "Expected output\n",
      "{\n",
      "  \"requirements_review\": [\n",
      "    {\n",
      "      \"requirement_id\": \"SYS-NAV-021\",\n",
      "      \"original\": \"The system shall use a Quad-Core ARM Cortex-A72 processor running at 2.0 GHz to ensure fast response.\",\n",
      "      \"checks\": {\n",
      "        \"L1\": {\"status\":\"pass\",\"Subject and shall — Names the item and uses ‘shall’.\":[\"Subject ‘The system’; uses ‘shall’\"],\"explanation\":\"Correct grammatical form.\"},\n",
      "        \"L2\": {\"status\":\"pass\",\"One per requirement — Only one enforceable statement.\":[\"Single enforceable statement\"],\"explanation\":\"One mandated design choice.\"},\n",
      "        \"L3\": {\"status\":\"fail\",\"Positive, active, clear — Explicit trigger/condition.\":[\"No condition; includes purpose clause ‘to ensure’\"],\"explanation\":\"Purpose clause introduces ambiguity.\"},\n",
      "        \"L4\": {\"status\":\"fail\",\"Measurable — Concrete criteria with units/tolerances/time.\":[\"‘fast response’ not defined\"],\"explanation\":\"Missing quantitative latency metric.\"},\n",
      "        \"L5\": {\"status\":\"pass\",\"Unambiguous wording — No vague terms/open-ended phrases.\":[\"CPU model/version explicit\"],\"explanation\":\"However, ambiguity in ‘fast response’ remains (covered in L4).\"},\n",
      "        \"T1\": {\"status\":\"fail\",\"Trace and necessity — Valid source/parent.\":[\"No contract-based mandate to fix CPU\"],\"explanation\":\"Design choice not justified by source under strict review.\"},\n",
      "        \"T2\": {\"status\":\"fail\",\"Right level of abstraction — States the ‘what’.\":[\"Premature design: specific CPU\"],\"explanation\":\"Should specify performance outcome instead of solution.\"},\n",
      "        \"T3\": {\"status\":\"fail\",\"Context and conditions — Modes/environments explicit.\":[\"No mode; environment conditions not stated\"],\"explanation\":\"Latency applicable to Teleop mode and ambient range needed.\"},\n",
      "        \"T4\": {\"status\":\"pass\",\"Values and units sanity — Direction/units/sig figs.\":[\"2.0 GHz specified but irrelevant if reframed\"],\"explanation\":\"Units are fine but not tied to performance need.\"},\n",
      "        \"T5\": {\"status\":\"pass\",\"Alignment with allocations/budgets — Roll-down correct.\":[\"Reframe to meet 80 ms E2E latency\"],\"explanation\":\"Performance budget exists to anchor rewrite.\"},\n",
      "        \"T6\": {\"status\":\"pass\",\"Feasibility — Achievable within margins.\":[\"200 Hz loop and 80 ms teleop latency feasible on COTS\"],\"explanation\":\"Consistent with budgets and utilization cap 80%.\"},\n",
      "        \"T7\": {\"status\":\"pass\",\"Interfaces precise — External items versioned.\":[\"IMU IF-IMU-1 v2.1; Drive IF-DRV-3 v1.4\"],\"explanation\":\"Interfaces identified for performance path.\"},\n",
      "        \"T8\": {\"status\":\"pass\",\"Standards/references — Exact identifier/revision.\":[\"No standard cited\"],\"explanation\":\"None required for latency metric.\"},\n",
      "        \"T9\": {\"status\":\"pass\",\"Exceptions/faults — Behavior under faults/edges.\":[\"Latency under temp range needs coverage in rewrite\"],\"explanation\":\"Rewrite will include temperature conditions.\"},\n",
      "        \"V1\": {\"status\":\"fail\",\"Pass/fail interpretation — Unambiguous decision.\":[\"Cannot test ‘fast response’\"],\"explanation\":\"Define measurable latency and sampling points.\"},\n",
      "        \"V2\": {\"status\":\"pass\",\"Verification method fit — T/A/I/D appropriate.\":[\"End-to-end latency test with HIL\"],\"explanation\":\"HIL testbed available per plan.\"},\n",
      "        \"V3\": {\"status\":\"fail\",\"Boundary tests — Worst-case/boundaries verifiable.\":[\"No boundary values provided\"],\"explanation\":\"Add worst-case temp and utilization conditions.\"},\n",
      "        \"V4\": {\"status\":\"pass\",\"Consistency — No conflicts with peers.\":[\"Aligns with SYS-NAV-020 200 Hz requirement if reframed\"],\"explanation\":\"No conflict when expressed as outcome.\"},\n",
      "        \"V5\": {\"status\":\"pass\",\"Redundancy — Not duplicative.\":[\"Unique performance aspect\"],\"explanation\":\"No duplicates found.\"},\n",
      "        \"V6\": {\"status\":\"pass\",\"TBD/TBR control — Placeholders managed.\":[\"No TBD/TBR\"],\"explanation\":\"N/A.\"}\n",
      "      },\n",
      "      \"proposed_rewrite\": \"While in Teleop mode and ambient temperature between -10 °C and 55 °C, the navigation computer shall execute the stabilization control loop at 200 Hz with end-to-end command latency ≤ 80 ms measured from operator input to actuator command, with processor utilization ≤ 80%.\",\n",
      "      \"split_recommendation\": {\"needed\": false, \"because\": \"Design constraint replaced by measurable performance requirement.\", \"split_into\": []}\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Example 3 — Multiple enforceable statements and vague term; recommend split\n",
      "Input\n",
      "- {{project_name}}: Helios-EMS HMI\n",
      "- {{output_language}}: English\n",
      "- {{review_context}}: INCOSE-style guidance as provided\n",
      "- {{requirements}}: [{\"id\":\"HMI-004\",\"text\":\"The display shall be user-friendly and display alerts in red and log all alerts to the database.\"}]\n",
      "- {{sources}}: {\"stakeholder\":\"STK-07 Situational awareness\",\"parent\":\"ALR-001 Alert visibility\"}\n",
      "- {{operational_context}}: {\"modes\":[\"Normal\",\"Alarm\"],\"environment\":{\"illum_lux\":[50,5000]}}\n",
      "- {{performance_budgets}}: {\"alert_visibility_ms\":200,\"log_latency_ms\":500}\n",
      "- {{verification_plan}}: {\"ALR-001\":\"Test alert colorimetry and timing; DB log inspection\"}\n",
      "- {{interfaces}}: {\"database\":\"IF-DB-2 v3.0\"}\n",
      "- {{standards}}: {\"colorimetry\":\"IEC 61966-2-1 sRGB\"}\n",
      "- {{glossary}}: {\"critical fault\":\"As defined in FMEA-001\"}\n",
      "- {{peer_requirements}}: []\n",
      "- {{constraints}}: {}\n",
      "- {{assumptions}}: {\"display_bg\":\"black\"}\n",
      "- {{strictness_level}}: normal\n",
      "- {{unit_system}}: SI\n",
      "- {{id_prefix}}: HMI\n",
      "- {{max_rewrites}}: 1\n",
      "\n",
      "Expected output\n",
      "{\n",
      "  \"requirements_review\": [\n",
      "    {\n",
      "      \"requirement_id\": \"HMI-004\",\n",
      "      \"original\": \"The display shall be user-friendly and display alerts in red and log all alerts to the database.\",\n",
      "      \"checks\": {\n",
      "        \"L1\": {\"status\":\"pass\",\"Subject and shall — Names the item and uses ‘shall’.\":[\"Subject ‘The display’; uses ‘shall’\"],\"explanation\":\"Correct form present.\"},\n",
      "        \"L2\": {\"status\":\"fail\",\"One per requirement — Only one enforceable statement.\":[\"Contains at least two actions: display alerts; log alerts\"],\"explanation\":\"Multiple enforceable statements joined by ‘and’.\"},\n",
      "        \"L3\": {\"status\":\"pass\",\"Positive, active, clear — Explicit trigger/condition.\":[\"Positive but lacks trigger\"],\"explanation\":\"Trigger will be added in rewrite.\"},\n",
      "        \"L4\": {\"status\":\"fail\",\"Measurable — Concrete criteria with units/tolerances/time.\":[\"‘user-friendly’ not measurable; ‘red’ not quantified\"],\"explanation\":\"Needs timing, color spec, and logging fields.\"},\n",
      "        \"L5\": {\"status\":\"fail\",\"Unambiguous wording — No vague terms/open-ended phrases.\":[\"Vague term: ‘user-friendly’\"],\"explanation\":\"Replace with testable criteria.\"},\n",
      "        \"T1\": {\"status\":\"pass\",\"Trace and necessity — Valid source/parent.\":[\"Traces to ALR-001\"],\"explanation\":\"Necessary for alert visibility and audit.\"},\n",
      "        \"T2\": {\"status\":\"pass\",\"Right level of abstraction — States the ‘what’.\":[\"UI behavior and logging outcomes\"],\"explanation\":\"No implementation details required.\"},\n",
      "        \"T3\": {\"status\":\"fail\",\"Context and conditions — Modes/environments explicit.\":[\"No mode; illumination range relevant\"],\"explanation\":\"Must state display conditions for visibility.\"},\n",
      "        \"T4\": {\"status\":\"fail\",\"Values and units sanity — Direction/units/sig figs.\":[\"Color and time metrics missing\"],\"explanation\":\"Add ms bounds and color spec (sRGB).\"},\n",
      "        \"T5\": {\"status\":\"pass\",\"Alignment with allocations/budgets — Roll-down correct.\":[\"200 ms display; 500 ms logging\"],\"explanation\":\"Budgets available to anchor numbers.\"},\n",
      "        \"T6\": {\"status\":\"pass\",\"Feasibility — Achievable within margins.\":[\"Feasible on current HMI\"],\"explanation\":\"Within hardware capabilities.\"},\n",
      "        \"T7\": {\"status\":\"pass\",\"Interfaces precise — External items versioned.\":[\"DB IF-DB-2 v3.0\"],\"explanation\":\"Interface identified for logging.\"},\n",
      "        \"T8\": {\"status\":\"pass\",\"Standards/references — Exact identifier/revision.\":[\"IEC 61966-2-1 sRGB\"],\"explanation\":\"Reference color space specified.\"},\n",
      "        \"T9\": {\"status\":\"pass\",\"Exceptions/faults — Behavior under faults/edges.\":[\"Not covered; acceptable if handled elsewhere\"],\"explanation\":\"Consider separate fault-display requirement.\"},\n",
      "        \"V1\": {\"status\":\"fail\",\"Pass/fail interpretation — Unambiguous decision.\":[\"Cannot test ‘user-friendly’\"],\"explanation\":\"Replace with quantitative criteria.\"},\n",
      "        \"V2\": {\"status\":\"pass\",\"Verification method fit — T/A/I/D appropriate.\":[\"Test for display timing/color; Inspection for log fields\"],\"explanation\":\"Facilities available.\"},\n",
      "        \"V3\": {\"status\":\"fail\",\"Boundary tests — Worst-case/boundaries verifiable.\":[\"No illumination or timing bounds\"],\"explanation\":\"Add lux range and timing limits.\"},\n",
      "        \"V4\": {\"status\":\"pass\",\"Consistency — No conflicts with peers.\":[\"No peers provided\"],\"explanation\":\"No conflicts identified.\"},\n",
      "        \"V5\": {\"status\":\"pass\",\"Redundancy — Not duplicative.\":[\"Unique behavior\"],\"explanation\":\"No duplicates found.\"},\n",
      "        \"V6\": {\"status\":\"pass\",\"TBD/TBR control — Placeholders managed.\":[\"No TBD/TBR\"],\"explanation\":\"N/A.\"}\n",
      "      },\n",
      "      \"proposed_rewrite\": \"When any critical fault as defined in FMEA-001 is detected under ambient illumination between 50 and 5000 lux, the HMI display shall present a red (#FF0000, sRGB) alert banner on a black background within 200 ms and persist it for at least 10 s.\",\n",
      "      \"split_recommendation\": {\n",
      "        \"needed\": true,\n",
      "        \"because\": \"Original contains multiple enforceable statements and a vague term; must decompose and quantify behaviors.\",\n",
      "        \"split_into\": [\n",
      "          \"When any critical fault as defined in FMEA-001 is detected under ambient illumination between 50 and 5000 lux, the HMI display shall present a red (#FF0000, sRGB) alert banner on a black background within 200 ms and persist it for at least 10 s.\",\n",
      "          \"When any alert is generated, the system shall append a record to the IF-DB-2 v3.0 incident log within 500 ms including timestamp (UTC), alert ID, severity, and source module.\"\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Now run with your provided inputs by replacing the {{variables}} above. Remember: return only the JSON object as specified under Output format.\n"
     ]
    }
   ],
   "source": [
    "print(structured_response.parsed.user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc61157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generated system message\n",
    "print(structured_response.parsed.system)\n",
    "with open(f\"{output_directory}/generated_system_message_accuracy.txt\", 'w', encoding=\"utf-8\") as f:\n",
    "    f.write(structured_response.parsed.system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5ea333",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generated user message\n",
    "print(structured_response.parsed.user)\n",
    "with open(f\"{output_directory}/generated_user_message_accuracy.txt\", 'w', encoding=\"utf-8\") as f:\n",
    "    f.write(structured_response.parsed.user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d3247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_=\"\"\"\n",
    "You are a senior systems engineering requirements quality analyst and technical editor. Apply the provided rules context rigorously, focusing on R2 Active Voice, R3 Appropriate Subject-Verb, R5 Definite Articles, R6 Common Units of Measure, R7 Vague Terms, R8 Escape Clauses, and R9 Open-Ended Clauses. Deliver precise, actionable critiques and high-quality rewrites that preserve the original intent. Do not introduce design beyond what is necessary to correct clarity or verifiability. If information is missing to comply with the rules, flag the ambiguity and propose placeholders rather than inventing facts. Be concise, direct, and consistent with the project’s glossary, entity scope, and measurement system.' user='Task\\n- Review and improve the supplied requirements against the provided rules context.\\n- Apply only the rules in {{rules_context}} unless explicitly told otherwise.\\n- Maintain original intent; if intent is unclear, note ambiguity and propose a conservative rewrite with placeholders.\\n- Align subjects to the declared entity scope and glossary.\\n- Use the chosen measurement system consistently.\\n- Write in {{output_language}}.\\n\\nInputs\\n- rules_context: {{rules_context}}\\n- entity_scope: {{entity_scope}}  (e.g., System level \"The <SOI> shall ...\"; Subsystem level \"The <subsystem> shall ...\"; Business management \"The <business> shall ...\")\\n- glossary: {{glossary}}  (key defined entities and terms, including intended \"User\")\\n- measurement_system: {{measurement_system}}  (e.g., Metric (SI) with degree Celsius, km, s; or US customary)\\n- project_patterns: {{project_patterns}}  (optional catalog of agreed patterns)\\n- requirements: {{requirements}}  (list of requirement statements to review)\\n- review_depth: {{review_depth}}  (brief | standard | deep)\\n- id_prefix: {{id_prefix}}  (optional, for numbering e.g., RQ)\\n- tone: {{tone}}  (e.g., crisp, coaching)\\n- output_language: {{output_language}}  (default English)\\n\\nOutput format\\nProvide exactly the following structure:\\n\\n1) Review Summary\\n- Scope: <echo entity_scope>\\n- Rules Applied: <list rule IDs from rules_context>\\n- Counts: <#requirements>, <#pass>, <#needs revision>\\n- Top Issues Observed: <bulleted list>\\n- Global Recommendations: <bulleted list>\\n\\n2) Per-Requirement Reviews\\nFor each requirement, in input order, produce:\\n- ID: <{{id_prefix}}-NN>\\n- Original: <verbatim requirement>\\n- Rule Checks\\n  - R2 Active Voice: <Pass|Fail> – <reason; identify subject and voice; show passive if present>\\n  - R3 Appropriate Subject-Verb: <Pass|Fail> – <is subject appropriate to entity_scope? verb appropriate to subject?>\\n  - R5 Definite Articles: <Pass|Fail> – <indefinite articles detected/replacements>\\n  - R6 Units: <Pass|Fail> – <units presence/consistency with measurement_system; property-element pairs>\\n  - R7 Vague Terms: <Pass|Fail> – <list terms found or None>\\n  - R8 Escape Clauses: <Pass|Fail> – <list phrases found or None>\\n  - R9 Open-Ended Clauses: <Pass|Fail> – <list phrases found or None>\\n- Overall Verdict: <Pass|Needs Revision>\\n- Improved Rewrite(s)\\n  - Minimal Change: <single minimally edited sentence>\\n  - Best-Practice Rewrite: <fully aligned with entity_scope, active voice, definite terms, precise units>\\n- Notes and Assumptions: <ambiguities, placeholders used, rationale for choices>\\n- Confidence: <High|Medium|Low>\\n\\n3) Red-Flag Index\\n- Vague Terms Found: <unique list>\\n- Escape Clauses Found: <unique list>\\n- Open-Ended Clauses Found: <unique list>\\n- Units At Risk: <elements needing units or unit harmonization>\\n\\nConstraints and Guidance\\n- R2: Use active voice. Identify the responsible entity as the grammatical subject; avoid \"shall be <past participle>\". Prefer \"The <entity> shall <verb> <object>\".\\n- R3: Ensure the subject matches the declared entity scope. Avoid subjects like \"The User\" for system requirements; use the entity from glossary (e.g., The <SOI>). Ensure verbs are concrete and verifiable.\\n- R5: Prefer the definite article \"the\" for defined entities. Replace \"a/an\" with \"the\" when referring to defined entities or roles per glossary.\\n- R6: State explicit units consistent with measurement_system. Do not mix systems. Keep consistent property-element unit pairs. Preserve precision when implying conversions; prefer placeholders if uncertain.\\n- R7: Remove vague qualifiers and adverbs. Replace with measurable, testable criteria.\\n- R8: Remove escape clauses like \"where possible\"; make the requirement unconditional or specify exact conditions.\\n- R9: Remove open-ended phrases like \"including but not limited to\", \"etc.\"; enumerate cases as separate requirements if needed.\\n- Do not alter domain meaning. If you must choose values to eliminate vagueness and none are provided, insert placeholders like <value>, <range>, <standard id> and flag in Notes.\\n\\nProcess\\n1) Parse {{requirements}} into individual statements; preserve order.\\n2) For each statement, test against each rule in {{rules_context}}.\\n3) Propose two improved rewrites (Minimal Change, Best-Practice) that comply with all applicable rules and align with {{entity_scope}}, {{glossary}}, and {{measurement_system}}.\\n4) Summarize systemic issues and recommend global fixes.\\n\\nExamples\\nExample A – System level\\n- Example Inputs\\n  - rules_context: R2, R3, R5, R6, R7, R8, R9\\n  - entity_scope: System – The Autopilot_System shall ...\\n  - glossary: User = certified pilot; Autopilot_System = SOI; Aircraft_Altitude, Cruise_Mode defined\\n  - measurement_system: Metric (SI); seconds (s), minutes (min), kilometres (km), degree Celsius (°C)\\n  - requirements:\\n    1. The User shall be notified of altitude deviations.\\n    2. While in Cruise_Mode, altitude shall be recorded every 5 min.\\n    3. The Autopilot_System shall display engine data, etc.\\n- Expected Output (abbreviated)\\n  1) Review Summary\\n  - Scope: System – The Autopilot_System shall ...\\n  - Rules Applied: R2, R3, R5, R6, R7, R8, R9\\n  - Counts: 3 total, 0 pass, 3 need revision\\n  - Top Issues Observed:\\n    - Passive voice and incorrect subject (R2, R3)\\n    - Missing definite articles and units precision (R5, R6)\\n    - Open-ended clause \"etc.\" (R9)\\n  - Global Recommendations:\\n    - Use \"The Autopilot_System\" as subject for system requirements\\n    - Replace \"etc.\" with explicit items or separate requirements\\n  2) Per-Requirement Reviews\\n  - ID: RQ-01\\n    Original: The User shall be notified of altitude deviations.\\n    Rule Checks\\n    - R2 Active Voice: Fail – Passive construction \"shall be notified\"; subject is \"The User\" receiving action\\n    - R3 Appropriate Subject-Verb: Fail – Subject should be The Autopilot_System; verb should describe system action (notify)\\n    - R5 Definite Articles: Pass – Uses \"The\"; but \"altitude deviations\" lacks defined object naming\\n    - R6 Units: Fail – No thresholds/units for deviation magnitude and time to notify\\n    - R7 Vague Terms: Fail – \"deviations\" undefined magnitude\\n    - R8 Escape Clauses: Pass – None\\n    - R9 Open-Ended Clauses: Pass – None\\n    Overall Verdict: Needs Revision\\n    Improved Rewrite(s)\\n    - Minimal Change: The Autopilot_System shall notify the Pilot of Aircraft_Altitude deviations greater than <Δaltitude_threshold> metres within <t_notify> seconds of detection.\\n    - Best-Practice Rewrite: The Autopilot_System shall notify the Pilot within <t_notify> s when the Aircraft_Altitude deviates by more than <Δaltitude_threshold> m from the Selected_Altitude while in the Cruise_Mode.\\n    Notes and Assumptions: Thresholds and time are placeholders pending stakeholder agreement.\\n    Confidence: Medium\\n  - ID: RQ-02\\n    Original: While in Cruise_Mode, altitude shall be recorded every 5 min.\\n    Rule Checks\\n    - R2: Fail – Missing responsible subject; passive implied\\n    - R3: Fail – Subject should be The Autopilot_System; verb should be \"record\"\\n    - R5: Fail – \"altitude\" should reference defined object (Aircraft_Altitude) with definite article\\n    - R6: Pass – Time unit provided (min) consistent with SI-accepted units\\n    - R7: Pass – No vague terms\\n    - R8: Pass – None\\n    - R9: Pass – None\\n    Overall Verdict: Needs Revision\\n    Improved Rewrite(s)\\n    - Minimal Change: While in the Cruise_Mode, the Autopilot_System shall record the Aircraft_Altitude every 5 min.\\n    - Best-Practice Rewrite: While in the Cruise_Mode, the Autopilot_System shall record the Aircraft_Altitude at a period of 5 min with a measurement precision of <precision> m.\\n    Notes and Assumptions: Added measurement precision placeholder to support verification.\\n    Confidence: High\\n  - ID: RQ-03\\n    Original: The Autopilot_System shall display engine data, etc.\\n    Rule Checks\\n    - R2: Pass – Active voice with correct subject\\n    - R3: Pass – Subject appropriate; verb concrete (display)\\n    - R5: Fail – \"engine data\" not specific/defined; no definite references\\n    - R6: Fail – No units for displayed quantities\\n    - R7: Fail – \"data\" unspecified (vague)\\n    - R8: Pass – None\\n    - R9: Fail – Contains \"etc.\"\\n    Overall Verdict: Needs Revision\\n    Improved Rewrite(s)\\n    - Minimal Change: The Autopilot_System shall display the Engine_RPM, Engine_Torque, and Engine_Oil_Temperature.\\n    - Best-Practice Rewrite: The Autopilot_System shall display the Engine_RPM (rev/min), Engine_Torque (N·m), and Engine_Oil_Temperature (°C) in accordance with <Display_Standard_ID>.\\n    Notes and Assumptions: Removed open-ended clause; enumerated key parameters. Add standard ID when known.\\n    Confidence: High\\n  3) Red-Flag Index\\n  - Vague Terms Found: data, deviations\\n  - Escape Clauses Found: None\\n  - Open-Ended Clauses Found: etc.\\n  - Units At Risk: deviation magnitude (m), notification time (s), display units for engine parameters\\n\\nExample B – Subsystem level\\n- Example Inputs\\n  - entity_scope: Subsystem – The Engine shall ...\\n  - glossary: Engine = Turboprop_Engine; Shaft_Power defined\\n  - measurement_system: Metric (SI)\\n  - requirements:\\n    1. An engine shall provide sufficient power.\\n    2. The Engine shall operate at temperatures less than 800 degrees.\\n- Expected Output (abbreviated)\\n  - RQ-01\\n    R2: Pass – Active; subject present\\n    R3: Fail – Indefinite subject (\"An engine\") for subsystem set; use \"The Engine\"\\n    R5: Fail – Indefinite article; vague noun phrase\\n    R6: Fail – No units for power\\n    R7: Fail – \"sufficient\" is vague\\n    R8: Pass – None\\n    R9: Pass – None\\n    Overall: Needs Revision\\n    Minimal Change: The Engine shall provide a Shaft_Power of at least <P_min> kW at <operating_condition>.\\n    Best-Practice: The Engine shall provide Shaft_Power ≥ <P_min> kW at Sea_Level ISA conditions and ≤ <altitude> m, <temperature> °C.\\n    Notes: Insert placeholders for testable thresholds and conditions.\\n  - RQ-02\\n    R2: Pass; R3: Pass\\n    R5: Pass – Uses \"The Engine\"\\n    R6: Fail – \"degrees\" missing scale\\n    R7: Pass\\n    R8: Pass\\n    R9: Pass\\n    Overall: Needs Revision\\n    Minimal Change: The Engine shall operate at temperatures less than or equal to 800 °C.\\n    Best-Practice: The Engine shall maintain Turbine_Inlet_Temperature ≤ 800 °C for a duration of <t> s at <power_setting>.\\n\\nExample C – Business management level\\n- Example Inputs\\n  - entity_scope: Business – The ACME_Company shall ...\\n  - glossary: ACME_Company defined; LTIFR defined\\n  - measurement_system: Metric (SI)\\n  - requirements:\\n    1. ACME shall be safe.\\n    2. The ACME_Company shall, where possible, reduce incidents.\\n- Expected Output (abbreviated)\\n  - RQ-01\\n    R2: Fail – Passive \"shall be\"; vague predicate\\n    R3: Pass – Subject aligns to business; verb inappropriate\\n    R5: Fail – Uses \"ACME\" inconsistently; prefer defined entity name\\n    R6: Pass – Not applicable, but measurable KPI missing\\n    R7: Fail – \"safe\" is vague\\n    R8: Pass\\n    R9: Pass\\n    Overall: Needs Revision\\n    Minimal Change: The ACME_Company shall achieve a Lost_Time_Injury_Frequency_Rate of ≤ <target> per 200,000 work hours by <date>.\\n    Best-Practice: The ACME_Company shall achieve LTIFR ≤ <target> per 200,000 work hours and Total_Recordable_Incident_Rate ≤ <target2> per 200,000 work hours by <date>.\\n  - RQ-02\\n    R2: Pass – Active\\n    R3: Pass – Subject appropriate\\n    R5: Pass\\n    R6: Pass – Not applicable\\n    R7: Pass – \"reduce\" measurable if quantified\\n    R8: Fail – Contains \"where possible\"\\n    R9: Pass\\n    Overall: Needs Revision\\n    Minimal Change: The ACME_Company shall reduce Safety_Incidents by at least <percentage>% year-over-year.\\n    Best-Practice: The ACME_Company shall reduce Safety_Incidents by ≥ <percentage>% year-over-year from the <baseline_year> baseline, measured quarterly.\\n\\nNow perform the review using the provided Inputs and produce the Output format exactly as specified.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cadc75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generated system message\n",
    "\"\"\"\n",
    "You are a Senior Requirements Quality Analyst and technical editor. You specialize in detecting and fixing requirement defects using authoritative quality rules. Be rigorous, consistent, and concise. Maintain the author’s technical intent while removing ambiguity. Do not add new functionality. Ask targeted clarification questions when needed.\n",
    "\n",
    "Authoritative rules to enforce (from the provided Context):\n",
    "- R7 Vague Terms: identify and replace vague quantifiers, adjectives, and adverbs with measurable, testable, and verifiable criteria.\n",
    "- R9 Open-Ended Clauses: remove open-ended phrases (e.g., “including but not limited to”, “etc.”, “and so on”); require explicit enumerations; recommend splitting into multiple atomic requirements if needed.\n",
    "- R12 Correct Grammar: ensure correct grammar, syntax, and punctuation to avoid ambiguity; correct tense/voice, subject-verb agreement, and modifier placement.\n",
    "- R38 Abbreviations: avoid ambiguous abbreviations; if an abbreviation is in the provided glossary with a single meaning, it may be retained (prefer first-use expansion); otherwise fully spell out.\n",
    "\n",
    "Style and constraints:\n",
    "- Output must strictly follow the Response Format specified below. Do not use Markdown or tables.\n",
    "- Keep wording precise, testable, and verifiable. Prefer active voice, singular characteristic per requirement.\n",
    "- If a numeric threshold is missing, use any provided quantitative defaults; otherwise mark as TBD and add a clarification question.\n",
    "- If input items lack IDs, auto-assign REQ-001, REQ-002, ... in order.\n",
    "- Do not remove domain terms; capitalize defined entities consistently.\n",
    "- Be self-consistent across all rewrites.\n",
    "\n",
    "Response Format (produce exactly this JSON structure):\n",
    "{\n",
    "  \"review_metadata\": {\n",
    "    \"domain\": \"<echo {{domain}}>\",\n",
    "    \"rules_applied\": [\"R7\", \"R9\", \"R12\", \"R38\"],\n",
    "    \"assumptions\": [\"<list any assumptions made>\"]\n",
    "  },\n",
    "  \"compliance_summary\": {\n",
    "    \"total_requirements\": <int>,\n",
    "    \"pass_count\": <int>,\n",
    "    \"fail_count\": <int>,\n",
    "    \"issues_by_rule\": {\n",
    "      \"R7\": <int>, \"R9\": <int>, \"R12\": <int>, \"R38\": <int>\n",
    "    }\n",
    "  },\n",
    "  \"requirements_review\": [\n",
    "    {\n",
    "      \"id\": \"<ID>\",\n",
    "      \"original\": \"<original requirement>\",\n",
    "      \"checks\": {\n",
    "        \"R7\": {\"status\": \"pass|fail\", \"vague_terms\": [\"<terms>\"], \"explanation\": \"<brief>\"},\n",
    "        \"R9\": {\"status\": \"pass|fail\", \"open_ended_phrases\": [\"<phrases>\"], \"explanation\": \"<brief>\"},\n",
    "        \"R12\": {\"status\": \"pass|fail\", \"grammar_issues\": [\"<issues>\"], \"explanation\": \"<brief>\"},\n",
    "        \"R38\": {\"status\": \"pass|fail\", \"abbreviations_found\": [\"<abbr>\"], \"actions\": \"<expand/retain/remove>\", \"explanation\": \"<brief>\"}\n",
    "      },\n",
    "      \"proposed_rewrite\": \"<single improved requirement that resolves all detected issues>\",\n",
    "      \"split_recommendation\": {\n",
    "        \"needed\": true|false,\n",
    "        \"because\": \"<why>\",\n",
    "        \"split_into\": [\"<Req A>\", \"<Req B>\"]\n",
    "      },\n",
    "      \"clarifying_questions\": [\"<question 1>\", \"<question 2>\"]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "Evaluation method:\n",
    "1) Parse inputs and normalize IDs. 2) For each requirement, test R7, R9, R12, R38. 3) Explain each failure succinctly. 4) Rewrite to a single, verifiable sentence unless a split is recommended. 5) Apply glossary rules for abbreviations; on first use of allowed abbreviations, prefer the expanded form with abbreviation in parentheses. 6) If required numbers are missing and no defaults are provided, use TBD placeholders and ask explicit questions to resolve them. 7) Summarize compliance.\n",
    "\n",
    "Important: If {{requirements}} is empty, respond with a single clarifying question requesting requirements to review and stop.\n",
    "\"\"\"\n",
    "\n",
    "## Generated user message\n",
    "\"\"\"\n",
    "Task: Review and improve the following requirement statements using the provided Context and variables.\n",
    "\n",
    "Context (authoritative rules):\n",
    "{{context}}\n",
    "\n",
    "Variables:\n",
    "- Domain: {{domain}}\n",
    "- Requirements (list or newline-separated; may include IDs):\n",
    "{{requirements}}\n",
    "- Project Glossary (abbreviations and definitions; JSON or list):\n",
    "{{glossary}}\n",
    "- Quantitative Defaults (JSON mapping of common thresholds; optional, e.g., {\"availability_threshold\":\"99.9%\",\"availability_window_hours\":\"720\",\"latency_seconds\":\"5\",\"proximity_km\":\"20\"}):\n",
    "{{quantitative_defaults}}\n",
    "- House Style Notes (nomenclature, capitalization, naming; optional):\n",
    "{{house_style}}\n",
    "- Max alternative rewrites per requirement (integer; default 1): {{max_rewrites_per_requirement}}\n",
    "- Enable split recommendations (true|false; default true): {{enable_split}}\n",
    "\n",
    "Produce output strictly in the Response Format JSON. Do not use Markdown.\n",
    "\n",
    "Examples\n",
    "\n",
    "Example 1 — Aviation domain with minimal glossary\n",
    "Input variables:\n",
    "- Domain: Aviation\n",
    "- Requirements:\n",
    "  REQ-1: The SOI shall usually be online.\n",
    "  REQ-2: The Flight_Information_System shall display per Display Standard xyz the Tracking_Information for relevant aircraft within 5 seconds of detection.\n",
    "  REQ-3: The op shall log events promptly.\n",
    "- Project Glossary:\n",
    "  ATC: Air Traffic Control\n",
    "- Quantitative Defaults:\n",
    "  {\"availability_threshold\":\"99.95%\",\"availability_window_hours\":\"720\",\"latency_seconds\":\"5\",\"proximity_km\":\"20\"}\n",
    "- Enable split recommendations: true\n",
    "\n",
    "Expected output (abbreviated):\n",
    "{\n",
    "  \"review_metadata\": {\"domain\": \"Aviation\", \"rules_applied\": [\"R7\",\"R9\",\"R12\",\"R38\"], \"assumptions\": []},\n",
    "  \"compliance_summary\": {\"total_requirements\": 3, \"pass_count\": 0, \"fail_count\": 3, \"issues_by_rule\": {\"R7\": 3, \"R9\": 1, \"R12\": 0, \"R38\": 1}},\n",
    "  \"requirements_review\": [\n",
    "    {\"id\": \"REQ-1\", \"original\": \"The SOI shall usually be online.\",\n",
    "     \"checks\": {\"R7\": {\"status\":\"fail\",\"vague_terms\":[\"usually\"],\"explanation\":\"Frequency not verifiable.\"},\n",
    "                 \"R9\": {\"status\":\"pass\",\"open_ended_phrases\":[],\"explanation\":\"\"},\n",
    "                 \"R12\": {\"status\":\"pass\",\"grammar_issues\":[],\"explanation\":\"\"},\n",
    "                 \"R38\": {\"status\":\"pass\",\"abbreviations_found\":[],\"actions\":\"retain\",\"explanation\":\"\"}},\n",
    "     \"proposed_rewrite\": \"The System_of_Interest (SOI) shall have an Availability of at least 99.95% measured over any rolling 720-hour period.\",\n",
    "     \"split_recommendation\": {\"needed\": false, \"because\": \"\", \"split_into\": []},\n",
    "     \"clarifying_questions\": []},\n",
    "\n",
    "    {\"id\": \"REQ-2\", \"original\": \"The Flight_Information_System shall display per Display Standard xyz the Tracking_Information for relevant aircraft within 5 seconds of detection.\",\n",
    "     \"checks\": {\"R7\": {\"status\":\"fail\",\"vague_terms\":[\"relevant\"],\"explanation\":\"Scope of aircraft is undefined.\"},\n",
    "                 \"R9\": {\"status\":\"pass\",\"open_ended_phrases\":[],\"explanation\":\"\"},\n",
    "                 \"R12\": {\"status\":\"pass\",\"grammar_issues\":[],\"explanation\":\"Word order acceptable but can be improved.\"},\n",
    "                 \"R38\": {\"status\":\"pass\",\"abbreviations_found\":[],\"actions\":\"retain\",\"explanation\":\"\"}},\n",
    "     \"proposed_rewrite\": \"The Flight_Information_System shall display, in accordance with Display Standard xyz, the Tracking_Information of each Aircraft located within 20 kilometers of the Airfield within 5 seconds of detection.\",\n",
    "     \"split_recommendation\": {\"needed\": false, \"because\": \"\", \"split_into\": []},\n",
    "     \"clarifying_questions\": [\"Confirm whether the proximity criterion is distance from Airfield, ATC Sector bounds, or another defined Control_Area.\"]},\n",
    "\n",
    "    {\"id\": \"REQ-3\", \"original\": \"The op shall log events promptly.\",\n",
    "     \"checks\": {\"R7\": {\"status\":\"fail\",\"vague_terms\":[\"promptly\"],\"explanation\":\"No latency target.\"},\n",
    "                 \"R9\": {\"status\":\"pass\",\"open_ended_phrases\":[],\"explanation\":\"\"},\n",
    "                 \"R12\": {\"status\":\"pass\",\"grammar_issues\":[],\"explanation\":\"\"},\n",
    "                 \"R38\": {\"status\":\"fail\",\"abbreviations_found\":[\"op\"],\"actions\":\"expand\",\"explanation\":\"'op' not defined in glossary.\"}},\n",
    "     \"proposed_rewrite\": \"The Operator shall record each Event within 5 seconds of occurrence.\",\n",
    "     \"split_recommendation\": {\"needed\": false, \"because\": \"\", \"split_into\": []},\n",
    "     \"clarifying_questions\": [\"Confirm whether 5 seconds is acceptable for event logging latency.\"]}\n",
    "  ]\n",
    "}\n",
    "\n",
    "Example 2 — Banking domain with defined abbreviations and open-ended clause\n",
    "Input variables:\n",
    "- Domain: Banking\n",
    "- Requirements:\n",
    "  1) The ATM shall display the Customer Account_Number, Account_Balance, and so on per Display Standard xyz.\n",
    "  2) The Weapon_System shall storing the location of all ordnance.\n",
    "  3) The website shall approximately load quickly.\n",
    "- Project Glossary:\n",
    "  ATM: Automated Teller Machine\n",
    "  PIN: Personal Identification Number\n",
    "- Quantitative Defaults:\n",
    "  {\"page_load_seconds\":\"2\"}\n",
    "- Enable split recommendations: true\n",
    "\n",
    "Expected output (abbreviated):\n",
    "{\n",
    "  \"review_metadata\": {\"domain\": \"Banking\", \"rules_applied\": [\"R7\",\"R9\",\"R12\",\"R38\"], \"assumptions\": [\"Treat numbered list as ordered requirements; auto-assign IDs.\"]},\n",
    "  \"compliance_summary\": {\"total_requirements\": 3, \"pass_count\": 0, \"fail_count\": 3, \"issues_by_rule\": {\"R7\": 2, \"R9\": 1, \"R12\": 1, \"R38\": 0}},\n",
    "  \"requirements_review\": [\n",
    "    {\"id\": \"REQ-001\", \"original\": \"The ATM shall display the Customer Account_Number, Account_Balance, and so on per Display Standard xyz.\",\n",
    "     \"checks\": {\"R7\": {\"status\":\"pass\",\"vague_terms\":[],\"explanation\":\"\"},\n",
    "                 \"R9\": {\"status\":\"fail\",\"open_ended_phrases\":[\"and so on\"],\"explanation\":\"Non-specific list.\"},\n",
    "                 \"R12\": {\"status\":\"pass\",\"grammar_issues\":[],\"explanation\":\"\"},\n",
    "                 \"R38\": {\"status\":\"pass\",\"abbreviations_found\":[\"ATM\"],\"actions\":\"retain\",\"explanation\":\"Defined in glossary; first use expanded.\"}},\n",
    "     \"proposed_rewrite\": \"The Automated Teller Machine (ATM) shall display the Customer Account_Number and Account_Balance in accordance with Display Standard xyz.\",\n",
    "     \"split_recommendation\": {\"needed\": true, \"because\": \"Multiple display elements and open-ended enumeration.\", \"split_into\": [\"The Automated Teller Machine (ATM) shall display the Customer Account_Number in accordance with Display Standard xyz.\", \"The Automated Teller Machine (ATM) shall display the Customer Account_Balance in accordance with Display Standard xyz.\"]},\n",
    "     \"clarifying_questions\": [\"List all additional fields to be displayed to replace 'and so on' (e.g., Account_Type, Overdraft_Limit).\"]},\n",
    "\n",
    "    {\"id\": \"REQ-002\", \"original\": \"The Weapon_System shall storing the location of all ordnance.\",\n",
    "     \"checks\": {\"R7\": {\"status\":\"pass\",\"vague_terms\":[],\"explanation\":\"\"},\n",
    "                 \"R9\": {\"status\":\"pass\",\"open_ended_phrases\":[],\"explanation\":\"\"},\n",
    "                 \"R12\": {\"status\":\"fail\",\"grammar_issues\":[\"incorrect verb form: 'shall storing'\"],\"explanation\":\"Use base verb after 'shall'.\"},\n",
    "                 \"R38\": {\"status\":\"pass\",\"abbreviations_found\":[],\"actions\":\"retain\",\"explanation\":\"\"}},\n",
    "     \"proposed_rewrite\": \"The Weapon_System shall store the location of all Ordnance.\",\n",
    "     \"split_recommendation\": {\"needed\": false, \"because\": \"Single action.\", \"split_into\": []},\n",
    "     \"clarifying_questions\": []},\n",
    "\n",
    "    {\"id\": \"REQ-003\", \"original\": \"The website shall approximately load quickly.\",\n",
    "     \"checks\": {\"R7\": {\"status\":\"fail\",\"vague_terms\":[\"approximately\",\"quickly\"],\"explanation\":\"Not measurable.\"},\n",
    "                 \"R9\": {\"status\":\"pass\",\"open_ended_phrases\":[],\"explanation\":\"\"},\n",
    "                 \"R12\": {\"status\":\"pass\",\"grammar_issues\":[],\"explanation\":\"\"},\n",
    "                 \"R38\": {\"status\":\"pass\",\"abbreviations_found\":[],\"actions\":\"retain\",\"explanation\":\"\"}},\n",
    "     \"proposed_rewrite\": \"The Website shall complete initial page load within 2 seconds for 95% of requests measured over any 24-hour period.\",\n",
    "     \"split_recommendation\": {\"needed\": false, \"because\": \"Single measurable characteristic.\", \"split_into\": []},\n",
    "     \"clarifying_questions\": [\"Confirm the percentile (e.g., 95% vs. 99%) and measurement window.\"]}\n",
    "  ]\n",
    "}\n",
    "\n",
    "Now perform the review on the provided inputs and return only the Response Format JSON.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe05203",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modify the prompt to return a simpler structure\n",
    "system_message_modified = \"\"\"\n",
    "You are a Senior Requirements Quality Analyst and technical editor. You specialize in detecting and fixing requirement defects using authoritative quality rules. Be rigorous, consistent, and concise. Maintain the author’s technical intent while removing ambiguity. Do not add new functionality. Ask targeted clarification questions when needed.\n",
    "\n",
    "Authoritative rules to enforce (from the provided Context):\n",
    "- R7 Vague Terms: identify and replace vague quantifiers, adjectives, and adverbs with measurable, testable, and verifiable criteria.\n",
    "- R9 Open-Ended Clauses: remove open-ended phrases (e.g., “including but not limited to”, “etc.”, “and so on”); require explicit enumerations; recommend splitting into multiple atomic requirements if needed.\n",
    "- R12 Correct Grammar: ensure correct grammar, syntax, and punctuation to avoid ambiguity; correct tense/voice, subject-verb agreement, and modifier placement.\n",
    "- R38 Abbreviations: avoid ambiguous abbreviations; if an abbreviation is in the provided glossary with a single meaning, it may be retained (prefer first-use expansion); otherwise fully spell out.\n",
    "\n",
    "Style and constraints:\n",
    "- Output must strictly follow the Response Format specified below. Do not use Markdown or tables.\n",
    "- Keep wording precise, testable, and verifiable. Prefer active voice, singular characteristic per requirement.\n",
    "- If a numeric threshold is missing, use any provided quantitative defaults; otherwise mark as TBD and add a clarification question.\n",
    "- If input items lack IDs, auto-assign REQ-001, REQ-002, ... in order.\n",
    "- Be self-consistent across all rewrites.\n",
    "\n",
    "Response Format (produce exactly this JSON structure):\n",
    "{\n",
    "  \"review_metadata\": {\n",
    "    \"rules_applied\": [\"R7\", \"R9\", \"R12\", \"R38\"],\n",
    "    \"assumptions\": [\"<list any assumptions made>\"]\n",
    "  },\n",
    "  \"compliance_summary\": {\n",
    "    \"pass_count\": <int>,\n",
    "    \"fail_count\": <int>,\n",
    "    \"issues_by_rule\": {\n",
    "      \"R7\": <int>, \"R9\": <int>, \"R12\": <int>, \"R38\": <int>\n",
    "    }\n",
    "  },\n",
    "  \"requirements_review\": [\n",
    "    {\n",
    "      \"id\": \"<ID>\",\n",
    "      \"original\": \"<original requirement>\",\n",
    "      \"checks\": {\n",
    "        \"R7\": {\"status\": \"pass|fail\", \"vague_terms\": [\"<terms>\"], \"explanation\": \"<brief>\"},\n",
    "        \"R9\": {\"status\": \"pass|fail\", \"open_ended_phrases\": [\"<phrases>\"], \"explanation\": \"<brief>\"},\n",
    "        \"R12\": {\"status\": \"pass|fail\", \"grammar_issues\": [\"<issues>\"], \"explanation\": \"<brief>\"},\n",
    "        \"R38\": {\"status\": \"pass|fail\", \"abbreviations_found\": [\"<abbr>\"], \"actions\": \"<expand/retain/remove>\", \"explanation\": \"<brief>\"}\n",
    "      },\n",
    "      \"proposed_rewrite\": \"<single improved requirement that resolves all detected issues>\",\n",
    "      \"split_recommendation\": {\n",
    "        \"needed\": true|false,\n",
    "        \"because\": \"<why>\",\n",
    "        \"split_into\": [\"<Req A>\", \"<Req B>\"]\n",
    "      },\n",
    "      \"clarifying_questions\": [\"<question 1>\", \"<question 2>\"]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "Evaluation method:\n",
    "1) Parse inputs and normalize IDs. 2) For each requirement, test R7, R9, R12, R38. 3) Explain each failure succinctly. 4) Rewrite to a single, verifiable sentence unless a split is recommended. 5) Apply glossary rules for abbreviations; on first use of allowed abbreviations, prefer the expanded form with abbreviation in parentheses. 6) If required numbers are missing and no defaults are provided, use TBD placeholders and ask explicit questions to resolve them. 7) Summarize compliance.\n",
    "\n",
    "Important: If {requirements} is empty, respond with a single clarifying question requesting requirements to review and stop.\n",
    "\"\"\"\n",
    "\n",
    "user_message_modified = \"\"\"\n",
    "Task: Review and improve the following requirement statements using the provided Context and variables.\n",
    "\n",
    "Context (authoritative rules):\n",
    "- R7 Vague Terms: identify and replace vague quantifiers, adjectives, and adverbs with measurable, testable, and verifiable criteria.\n",
    "- R9 Open-Ended Clauses: remove open-ended phrases (e.g., “including but not limited to”, “etc.”, “and so on”); require explicit enumerations; recommend splitting into multiple atomic requirements if needed.\n",
    "- R12 Correct Grammar: ensure correct grammar, syntax, and punctuation to avoid ambiguity; correct tense/voice, subject-verb agreement, and modifier placement.\n",
    "- R38 Abbreviations: avoid ambiguous abbreviations; if an abbreviation is in the provided glossary with a single meaning, it may be retained (prefer first-use expansion); otherwise fully spell out.\n",
    "\n",
    "Variables:\n",
    "- Requirements (list or newline-separated; may include IDs):\n",
    "{requirements}\n",
    "- Enable split recommendations (true|false; default true): {enable_split}\n",
    "\n",
    "Produce output strictly in the Response Format JSON. Do not use Markdown.\n",
    "\n",
    "Examples\n",
    "\n",
    "Example 1 — Aviation domain with minimal glossary\n",
    "Input variables:\n",
    "- Requirements:\n",
    "  REQ-1: The SOI shall usually be online.\n",
    "  REQ-2: The Flight_Information_System shall display per Display Standard xyz the Tracking_Information for relevant aircraft within 5 seconds of detection.\n",
    "  REQ-3: The op shall log events promptly.\n",
    "- Enable split recommendations: true\n",
    "\n",
    "Expected output (abbreviated):\n",
    "{\n",
    "  \"review_metadata\": {\"rules_applied\": [\"R7\",\"R9\",\"R12\",\"R38\"], \"assumptions\": []},\n",
    "  \"compliance_summary\": {\"total_requirements\": 3, \"pass_count\": 0, \"fail_count\": 3, \"issues_by_rule\": {\"R7\": 3, \"R9\": 1, \"R12\": 0, \"R38\": 1}},\n",
    "  \"requirements_review\": [\n",
    "    {\"id\": \"REQ-1\", \"original\": \"The SOI shall usually be online.\",\n",
    "     \"checks\": {\"R7\": {\"status\":\"fail\",\"vague_terms\":[\"usually\"],\"explanation\":\"Frequency not verifiable.\"},\n",
    "                 \"R9\": {\"status\":\"pass\",\"open_ended_phrases\":[],\"explanation\":\"\"},\n",
    "                 \"R12\": {\"status\":\"pass\",\"grammar_issues\":[],\"explanation\":\"\"},\n",
    "                 \"R38\": {\"status\":\"pass\",\"abbreviations_found\":[],\"actions\":\"retain\",\"explanation\":\"\"}},\n",
    "     \"proposed_rewrite\": \"The System_of_Interest (SOI) shall have an Availability of at least 99.95% measured over any rolling 720-hour period.\",\n",
    "     \"split_recommendation\": {\"needed\": false, \"because\": \"\", \"split_into\": []},\n",
    "     \"clarifying_questions\": []},\n",
    "\n",
    "    {\"id\": \"REQ-2\", \"original\": \"The Flight_Information_System shall display per Display Standard xyz the Tracking_Information for relevant aircraft within 5 seconds of detection.\",\n",
    "     \"checks\": {\"R7\": {\"status\":\"fail\",\"vague_terms\":[\"relevant\"],\"explanation\":\"Scope of aircraft is undefined.\"},\n",
    "                 \"R9\": {\"status\":\"pass\",\"open_ended_phrases\":[],\"explanation\":\"\"},\n",
    "                 \"R12\": {\"status\":\"pass\",\"grammar_issues\":[],\"explanation\":\"Word order acceptable but can be improved.\"},\n",
    "                 \"R38\": {\"status\":\"pass\",\"abbreviations_found\":[],\"actions\":\"retain\",\"explanation\":\"\"}},\n",
    "     \"proposed_rewrite\": \"The Flight_Information_System shall display, in accordance with Display Standard xyz, the Tracking_Information of each Aircraft located within 20 kilometers of the Airfield within 5 seconds of detection.\",\n",
    "     \"split_recommendation\": {\"needed\": false, \"because\": \"\", \"split_into\": []},\n",
    "     \"clarifying_questions\": [\"Confirm whether the proximity criterion is distance from Airfield, ATC Sector bounds, or another defined Control_Area.\"]},\n",
    "\n",
    "    {\"id\": \"REQ-3\", \"original\": \"The op shall log events promptly.\",\n",
    "     \"checks\": {\"R7\": {\"status\":\"fail\",\"vague_terms\":[\"promptly\"],\"explanation\":\"No latency target.\"},\n",
    "                 \"R9\": {\"status\":\"pass\",\"open_ended_phrases\":[],\"explanation\":\"\"},\n",
    "                 \"R12\": {\"status\":\"pass\",\"grammar_issues\":[],\"explanation\":\"\"},\n",
    "                 \"R38\": {\"status\":\"fail\",\"abbreviations_found\":[\"op\"],\"actions\":\"expand\",\"explanation\":\"'op' not defined in glossary.\"}},\n",
    "     \"proposed_rewrite\": \"The Operator shall record each Event within 5 seconds of occurrence.\",\n",
    "     \"split_recommendation\": {\"needed\": false, \"because\": \"\", \"split_into\": []},\n",
    "     \"clarifying_questions\": [\"Confirm whether 5 seconds is acceptable for event logging latency.\"]}\n",
    "  ]\n",
    "}\n",
    "\n",
    "Example 2 — Banking domain with defined abbreviations and open-ended clause\n",
    "Input variables:\n",
    "- Requirements:\n",
    "  1) The ATM shall display the Customer Account_Number, Account_Balance, and so on per Display Standard xyz.\n",
    "  2) The Weapon_System shall storing the location of all ordnance.\n",
    "  3) The website shall approximately load quickly.\n",
    "- Enable split recommendations: true\n",
    "\n",
    "Expected output (abbreviated):\n",
    "{\n",
    "  \"review_metadata\": {\"rules_applied\": [\"R7\",\"R9\",\"R12\",\"R38\"], \"assumptions\": [\"Treat numbered list as ordered requirements; auto-assign IDs.\"]},\n",
    "  \"compliance_summary\": {\"total_requirements\": 3, \"pass_count\": 0, \"fail_count\": 3, \"issues_by_rule\": {\"R7\": 2, \"R9\": 1, \"R12\": 1, \"R38\": 0}},\n",
    "  \"requirements_review\": [\n",
    "    {\"id\": \"REQ-001\", \"original\": \"The ATM shall display the Customer Account_Number, Account_Balance, and so on per Display Standard xyz.\",\n",
    "     \"checks\": {\"R7\": {\"status\":\"pass\",\"vague_terms\":[],\"explanation\":\"\"},\n",
    "                 \"R9\": {\"status\":\"fail\",\"open_ended_phrases\":[\"and so on\"],\"explanation\":\"Non-specific list.\"},\n",
    "                 \"R12\": {\"status\":\"pass\",\"grammar_issues\":[],\"explanation\":\"\"},\n",
    "                 \"R38\": {\"status\":\"pass\",\"abbreviations_found\":[\"ATM\"],\"actions\":\"retain\",\"explanation\":\"Defined in glossary; first use expanded.\"}},\n",
    "     \"proposed_rewrite\": \"The Automated Teller Machine (ATM) shall display the Customer Account_Number and Account_Balance in accordance with Display Standard xyz.\",\n",
    "     \"split_recommendation\": {\"needed\": true, \"because\": \"Multiple display elements and open-ended enumeration.\", \"split_into\": [\"The Automated Teller Machine (ATM) shall display the Customer Account_Number in accordance with Display Standard xyz.\", \"The Automated Teller Machine (ATM) shall display the Customer Account_Balance in accordance with Display Standard xyz.\"]},\n",
    "     \"clarifying_questions\": [\"List all additional fields to be displayed to replace 'and so on' (e.g., Account_Type, Overdraft_Limit).\"]},\n",
    "\n",
    "    {\"id\": \"REQ-002\", \"original\": \"The Weapon_System shall storing the location of all ordnance.\",\n",
    "     \"checks\": {\"R7\": {\"status\":\"pass\",\"vague_terms\":[],\"explanation\":\"\"},\n",
    "                 \"R9\": {\"status\":\"pass\",\"open_ended_phrases\":[],\"explanation\":\"\"},\n",
    "                 \"R12\": {\"status\":\"fail\",\"grammar_issues\":[\"incorrect verb form: 'shall storing'\"],\"explanation\":\"Use base verb after 'shall'.\"},\n",
    "                 \"R38\": {\"status\":\"pass\",\"abbreviations_found\":[],\"actions\":\"retain\",\"explanation\":\"\"}},\n",
    "     \"proposed_rewrite\": \"The Weapon_System shall store the location of all Ordnance.\",\n",
    "     \"split_recommendation\": {\"needed\": false, \"because\": \"Single action.\", \"split_into\": []},\n",
    "     \"clarifying_questions\": []},\n",
    "\n",
    "    {\"id\": \"REQ-003\", \"original\": \"The website shall approximately load quickly.\",\n",
    "     \"checks\": {\"R7\": {\"status\":\"fail\",\"vague_terms\":[\"approximately\",\"quickly\"],\"explanation\":\"Not measurable.\"},\n",
    "                 \"R9\": {\"status\":\"pass\",\"open_ended_phrases\":[],\"explanation\":\"\"},\n",
    "                 \"R12\": {\"status\":\"pass\",\"grammar_issues\":[],\"explanation\":\"\"},\n",
    "                 \"R38\": {\"status\":\"pass\",\"abbreviations_found\":[],\"actions\":\"retain\",\"explanation\":\"\"}},\n",
    "     \"proposed_rewrite\": \"The Website shall complete initial page load within 2 seconds for 95% of requests measured over any 24-hour period.\",\n",
    "     \"split_recommendation\": {\"needed\": false, \"because\": \"Single measurable characteristic.\", \"split_into\": []},\n",
    "     \"clarifying_questions\": [\"Confirm the percentile (e.g., 95% vs. 99%) and measurement window.\"]}\n",
    "  ]\n",
    "}\n",
    "\n",
    "Now perform the review on the provided inputs and return only the Response Format JSON.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c6593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run prompt\n",
    "\n",
    "import pandas as pd\n",
    "# Load requirements\n",
    "df = pd.read_excel('../src/data/demo_dataset.xlsx')\n",
    "requirement_col = 'requirement'\n",
    "#id_col = 'requirement_#'\n",
    "#ids = list(df[id_col].values)[0:5]\n",
    "requirements = list(df[requirement_col].values)[0:5]\n",
    "\n",
    "# Create OpenAI instance\n",
    "client = OpenAI(\n",
    "    # Replace with your actual API key or use: api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=openai_api_key_secret.get_secret_value()\n",
    ")\n",
    "resp_client = ResponseClient(client=client, model=\"gpt-4o-mini\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message_modified},\n",
    "    {\"role\": \"user\", \"content\": user_message_modified.replace('{requirements}', '\\n'.join(requirements)).replace('{enable_split}', 'True')}\n",
    "]\n",
    "structured_response = resp_client.get_structured_response(\n",
    "    messages=messages,\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "resp_client.check_structured_output(structured_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cb132c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(structured_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a24d921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "response_json = json.loads(structured_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3a31f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flatdict\n",
    "from src import utils\n",
    "nested_dict = response_json['requirements_review']\n",
    "flat_dict = [flatdict.FlatDict(n, delimiter='.') for n in nested_dict]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e655aad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "revisions_df = pd.DataFrame(flat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130f9e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "revisions_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd0e09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.components import prompteval as pe\n",
    "## Run evaluations\n",
    "# Functions currently requiring remediation\n",
    "exclude_funcs = [\n",
    "    'eval_explicit_enumeration',\n",
    "    'eval_follows_style_guide',\n",
    "    'eval_has_correct_grammar',\n",
    "    'eval_has_supporting_diagram_or_model_reference',\n",
    "    'eval_is_structured_set',\n",
    "    'eval_is_unique_expression',\n",
    "    'eval_has_explicit_conditions_for_single_action',\n",
    "    'eval_is_structured_statement'\n",
    "]\n",
    "# Make evaluation function config\n",
    "eval_config = pe.make_eval_config(pe, exclude_funcs=exclude_funcs)\n",
    "# Call the evaluations on the dataframe \n",
    "eval_df = pe.call_evals(revisions_df, col='original', eval_config=eval_config)\n",
    "# Get list of failed eval functions\n",
    "eval_df = pe.get_failed_evals(eval_df)\n",
    "# Map the failed eval functions to rule groups (as defined in the config.yaml file)\n",
    "eval_df = pe.map_failed_eval_col_to_rule_group(eval_df, eval_to_rule_map=config[\"SECTION_4_RULE_GROUPS\"], failed_eval_col='failed_evals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20063331",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b143210c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.components import prompteval as pe\n",
    "## Run evaluations\n",
    "# Functions currently requiring remediation\n",
    "exclude_funcs = [\n",
    "    'eval_explicit_enumeration',\n",
    "    'eval_follows_style_guide',\n",
    "    'eval_has_correct_grammar',\n",
    "    'eval_has_supporting_diagram_or_model_reference',\n",
    "    'eval_is_structured_set',\n",
    "    'eval_is_unique_expression',\n",
    "    'eval_has_explicit_conditions_for_single_action',\n",
    "    'eval_is_structured_statement'\n",
    "]\n",
    "# Make evaluation function config\n",
    "eval_config = pe.make_eval_config(pe, exclude_funcs=exclude_funcs)\n",
    "# Call the evaluations on the dataframe \n",
    "eval_df = pe.call_evals(revisions_df, col='proposed_rewrite', eval_config=eval_config)\n",
    "# Get list of failed eval functions\n",
    "eval_df = pe.get_failed_evals(eval_df)\n",
    "# Map the failed eval functions to rule groups (as defined in the config.yaml file)\n",
    "eval_df = pe.map_failed_eval_col_to_rule_group(eval_df, eval_to_rule_map=config[\"SECTION_4_RULE_GROUPS\"], failed_eval_col='failed_evals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa7f0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cdb225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
