{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c32602e9",
   "metadata": {},
   "source": [
    "This project (titled `aiswre`) seeks to integrate the best practices described in the INCOSE Guide to Writing Requirements to enhance software requirement quality using NLP and AI.\n",
    "\n",
    "### Overview of the `aiswre` project\n",
    "\n",
    "This project, `aiswre` intends to apply AI, NLP, and data science methodologies to improve the quality of software quality processes. The initial features of the project focus on using prompt engineering techniques to refine software requirements based on the rules described in section 4 of the [INCOSE Guide](https://www.incose.org/docs/default-source/working-groups/requirements-wg/gtwr/incose_rwg_gtwr_v4_040423_final_drafts.pdf?sfvrsn=5c877fc7_2). This project was inspired by the desire to enhance the field of software quality with AI and system engineering best practices. Application of LLMs bear the opportunity to advance the field of requirements engineering as initial studies have shown promising results<sup>1,2</sup>.\n",
    "\n",
    "### Design description\n",
    "\n",
    "The project will take a requirement as input, assess it against a variety of criteria, and based on the identified gaps, refine the requirement to align with rules as described in INCOSE Guide to Writing Requirements Section 4. At present, the application only leverages the input requirement and INCOSE Guide (no other information about the project) to perform the revision.\n",
    "\n",
    "### Getting started\n",
    "\n",
    "- Set up your OpenAI API key [OPEN AI Developer quickstart](https://platform.openai.com/)\n",
    "- Add requirements dataset to the directory\n",
    "- Open a powershell terminal and enter the following to clone the repository:\n",
    "\t- `git clone https://github.com/dsobczynski88/aiswre.git <your_desired_folder_name>`\n",
    "- Navigate to the folder containing the cloned repository:\n",
    "\t- `cd <your_desired_folder_name>`\n",
    "- Create a blank `.env` file in this location and enter:\n",
    "\t- `OPENAI_API_KEY = <your_api_key>`\n",
    "- Create a virtual env:\n",
    "\t- `python -m venv venv` \n",
    "- Activate the environment (Windows Powershell):\n",
    "\t- `.\\\\venv\\Scripts\\activate.bat`\n",
    "- Enter the following commands to install the code and dependencies:\n",
    "\t- `python -m pip install -r requirements.txt`\n",
    "\t- `python -m pip install -e .`\n",
    "\n",
    "### Future Work\n",
    "\n",
    "Prompt engineering best practices have been applied to improve the results. However at present, this work is structured in a pre-defined way that confines the workflow. The program itself may benefit from usage of more advanced approaches in AI such as langgraph flows and agent frameworks. Furthermore, the work at best is designed for a handful of INCOSE rules and therefore is still in progress. To improve the robustness and utility of this work, there are opportunities to leverage more efficient design patterns, and this too is a subject of ongoing project activities.\n",
    "\n",
    "### Example Usage\n",
    "\n",
    "**INCOSE-Based Requirement Review**\n",
    "\n",
    "Enter from the command line: `python scripts/readme_req_reviewer_example.py` \n",
    "\n",
    "Source code file:\n",
    "```python\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "from dotenv import dotenv_values\n",
    "from src import utils\n",
    "from src.components import prompteval as pe\n",
    "from src.components.promptrunner import RateLimitOpenAIClient\n",
    "from src.components.promptprocessor import PromptProcessor  \n",
    "from src.utils import load_prompt\n",
    "\n",
    "# ===============================================================\n",
    "# Configuration\n",
    "# ===============================================================\n",
    "DOT_ENV = dotenv_values(\".env\")\n",
    "CONFIG = utils.load_config(\"config.yaml\")\n",
    "MODEL = CONFIG[\"MODEL\"]\n",
    "MODEL_KWARGS = CONFIG[\"MODEL_KWARGS\"]\n",
    "PROMPT_TEMPLATE_PATH = CONFIG[\"FILE_LOCATIONS\"][\"PROMPT_TEMPLATE_PATH\"]\n",
    "PROMPT_NAME = CONFIG[\"PROMPT_TEMPLATE\"]\n",
    "OPENAI_API_KEY = DOT_ENV[\"OPENAI_API_KEY\"]\n",
    "MAX_REQUESTS_PER_MIN = 490\n",
    "MAX_TOKENS_PER_MIN = 200000\n",
    "OUTPUT_DIRECTORY = utils.make_output_directory(CONFIG[\"FILE_LOCATIONS\"], \"OUTPUT_FOLDER\")\n",
    "SYSTEM_PROMPT = load_prompt(PROMPT_TEMPLATE_PATH, PROMPT_NAME, \"system\")\n",
    "USER_PROMPT_TEMPLATE = load_prompt(PROMPT_TEMPLATE_PATH, PROMPT_NAME, \"user\")\n",
    "DATASET_FILE_PATH = CONFIG[\"FILE_LOCATIONS\"][\"DATASET_FILE_PATH\"]\n",
    "SELECTED_EVAL_FUNCS = CONFIG[\"SELECTED_EVAL_FUNCS\"]\n",
    "SELECTED_EVAL_WEIGHTS = CONFIG[\"SELECTED_EVAL_WEIGHTS\"]\n",
    "EVAL_CONFIG = pe.make_eval_config(pe, include_funcs=SELECTED_EVAL_FUNCS)\n",
    "\n",
    "# ===============================================================\n",
    "# Input requirements\n",
    "# ===============================================================\n",
    "df_input = pd.read_excel(DATASET_FILE_PATH)\n",
    "\n",
    "# ===============================================================\n",
    "# Instantiate LLM client\n",
    "# ===============================================================\n",
    "rl_client = RateLimitOpenAIClient(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    max_requests_per_minute=MAX_REQUESTS_PER_MIN,\n",
    "    max_tokens_per_minute=MAX_TOKENS_PER_MIN\n",
    "    )\n",
    "\n",
    "# ===============================================================\n",
    "# Async runner\n",
    "# ===============================================================\n",
    "async def run_req_review_with_processor(client, input_df, model, model_kwargs):\n",
    "    processor = PromptProcessor(client=client, input_df=input_df, model=model, model_kwargs=model_kwargs)\n",
    "    items = processor.df_to_prompt_items(df_input, [\"requirement_id\", \"requirements\"])\n",
    "    ids = [item[\"requirement_id\"] for item in items]\n",
    "    results = await processor.run_prompt_batch(\n",
    "        system_message=SYSTEM_PROMPT,\n",
    "        user_message_template=USER_PROMPT_TEMPLATE,\n",
    "        prompt_name=PROMPT_NAME,\n",
    "        items=items,\n",
    "        ids=ids,\n",
    "    )\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ===============================================================\n",
    "# Main execution\n",
    "# ===============================================================\n",
    "review_df = asyncio.run(run_req_review_with_processor(rl_client, df_input, MODEL, MODEL_KWARGS))\n",
    "review_df = pe.call_evals(review_df, col=\"requirements_review.proposed_rewrite\", eval_config=EVAL_CONFIG)\n",
    "review_df = pe.get_failed_evals(review_df)\n",
    "pe.add_weighted_column(review_df, SELECTED_EVAL_FUNCS, SELECTED_EVAL_WEIGHTS, \"weighted_value\")    \n",
    "review_df.to_excel(f\"{OUTPUT_DIRECTORY}/reviewed_requirements.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc348c8b",
   "metadata": {},
   "source": [
    "#### End-to-end workflow for AI-assisted requirement reviews and revisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fdb4520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "from src import utils\n",
    "\n",
    "# Load config settings\n",
    "DOT_ENV = dotenv_values(\"../.env\")\n",
    "config = utils.load_config(\"../config.yaml\")\n",
    "\n",
    "# Create a unique run-id folder to store outputs\n",
    "config[\"FILE_LOCATIONS\"][\"MAIN_DATA_FOLDER\"] = \"../src/data\"\n",
    "output_directory = utils.make_output_directory(config[\"FILE_LOCATIONS\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d16c7f",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "# Load requirements\n",
    "df = pd.read_excel('../src/data/demo_dataset.xlsx')\n",
    "requirement_col = 'requirement'\n",
    "id_col = 'requirement_#'\n",
    "requirements = list(df[requirement_col].values)\n",
    "ids = list(df[id_col].values)\n",
    "print(ids)\n",
    "print(requirements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b51331d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from src.components import prompteval as pe\n",
    "## Run evaluations\n",
    "# Functions currently requiring remediation\n",
    "exclude_funcs = [\n",
    "    'eval_explicit_enumeration',\n",
    "    'eval_follows_style_guide',\n",
    "    'eval_has_correct_grammar',\n",
    "    'eval_has_supporting_diagram_or_model_reference',\n",
    "    'eval_is_structured_set',\n",
    "    'eval_is_unique_expression',\n",
    "    'eval_has_explicit_conditions_for_single_action',\n",
    "    'eval_is_structured_statement'\n",
    "]\n",
    "# Make evaluation function config\n",
    "eval_config = pe.make_eval_config(pe, exclude_funcs=exclude_funcs)\n",
    "# Call the evaluations on the dataframe \n",
    "eval_df = pe.call_evals(df, col=requirement_col, eval_config=eval_config)\n",
    "# Get list of failed eval functions\n",
    "eval_df = pe.get_failed_evals(eval_df)\n",
    "# Map the failed eval functions to rule groups (as defined in the config.yaml file)\n",
    "eval_df = pe.map_failed_eval_col_to_rule_group(eval_df, eval_to_rule_map=config[\"SECTION_4_RULE_GROUPS\"], failed_eval_col='failed_evals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36dfa5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>requirement_#</th>\n",
       "      <th>requirement</th>\n",
       "      <th>eval_acronym_consistency</th>\n",
       "      <th>eval_avoid_pronouns</th>\n",
       "      <th>eval_avoids_absolutes</th>\n",
       "      <th>eval_avoids_parentheses</th>\n",
       "      <th>eval_avoids_purpose_phrases</th>\n",
       "      <th>eval_avoids_vague_terms</th>\n",
       "      <th>eval_consistent_terms_and_units</th>\n",
       "      <th>...</th>\n",
       "      <th>eval_is_singular_statement</th>\n",
       "      <th>eval_is_solution_free</th>\n",
       "      <th>eval_logical_expressions</th>\n",
       "      <th>eval_no_oblique_symbol</th>\n",
       "      <th>eval_terms_are_defined</th>\n",
       "      <th>eval_uses_abbreviations</th>\n",
       "      <th>eval_uses_not</th>\n",
       "      <th>eval_uses_universal_qualification</th>\n",
       "      <th>failed_evals</th>\n",
       "      <th>failed_evals_rule_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The Disputes System shall record the name of t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[eval_avoid_pronouns, eval_avoids_absolutes, e...</td>\n",
       "      <td>[Completeness, Realism, Abstraction, Accuracy,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The WCS system shall use appropriate nomenclat...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[eval_acronym_consistency, eval_avoid_pronouns...</td>\n",
       "      <td>[Uniformity_Of_Language, Completeness, Realism...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The system will notify affected parties when ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[eval_avoids_purpose_phrases, eval_consistent_...</td>\n",
       "      <td>[Abstraction, Quantification, Uniformity_Of_La...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Application testability DESC: Test environment...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[eval_acronym_consistency, eval_avoids_absolut...</td>\n",
       "      <td>[Uniformity_Of_Language, Realism, Abstraction,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The product shall be platform independent.The ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[eval_avoid_pronouns, eval_avoids_absolutes, e...</td>\n",
       "      <td>[Completeness, Realism, Abstraction, Accuracy,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  requirement_#  \\\n",
       "0           0              0   \n",
       "1           1              1   \n",
       "2           2              2   \n",
       "3           3              3   \n",
       "4           4              4   \n",
       "\n",
       "                                         requirement  \\\n",
       "0  The Disputes System shall record the name of t...   \n",
       "1  The WCS system shall use appropriate nomenclat...   \n",
       "2   The system will notify affected parties when ...   \n",
       "3  Application testability DESC: Test environment...   \n",
       "4  The product shall be platform independent.The ...   \n",
       "\n",
       "   eval_acronym_consistency  eval_avoid_pronouns  eval_avoids_absolutes  \\\n",
       "0                       1.0                  0.0                    0.0   \n",
       "1                       0.0                  0.0                    0.0   \n",
       "2                       1.0                  1.0                    1.0   \n",
       "3                       0.0                  1.0                    0.0   \n",
       "4                       1.0                  0.0                    0.0   \n",
       "\n",
       "   eval_avoids_parentheses  eval_avoids_purpose_phrases  \\\n",
       "0                      1.0                          0.0   \n",
       "1                      1.0                          1.0   \n",
       "2                      1.0                          0.0   \n",
       "3                      1.0                          0.0   \n",
       "4                      1.0                          0.0   \n",
       "\n",
       "   eval_avoids_vague_terms  eval_consistent_terms_and_units  ...  \\\n",
       "0                      0.0                              0.0  ...   \n",
       "1                      0.0                              0.0  ...   \n",
       "2                      1.0                              0.0  ...   \n",
       "3                      1.0                              0.0  ...   \n",
       "4                      0.0                              0.0  ...   \n",
       "\n",
       "   eval_is_singular_statement  eval_is_solution_free  \\\n",
       "0                         0.0                    0.0   \n",
       "1                         0.0                    0.0   \n",
       "2                         1.0                    1.0   \n",
       "3                         1.0                    1.0   \n",
       "4                         1.0                    0.0   \n",
       "\n",
       "   eval_logical_expressions  eval_no_oblique_symbol  eval_terms_are_defined  \\\n",
       "0                       0.0                     1.0                     1.0   \n",
       "1                       0.0                     1.0                     0.0   \n",
       "2                       0.0                     1.0                     1.0   \n",
       "3                       1.0                     1.0                     0.0   \n",
       "4                       0.0                     1.0                     1.0   \n",
       "\n",
       "   eval_uses_abbreviations  eval_uses_not  eval_uses_universal_qualification  \\\n",
       "0                      1.0            1.0                                0.0   \n",
       "1                      0.0            1.0                                0.0   \n",
       "2                      1.0            0.0                                1.0   \n",
       "3                      0.0            1.0                                1.0   \n",
       "4                      1.0            1.0                                0.0   \n",
       "\n",
       "                                        failed_evals  \\\n",
       "0  [eval_avoid_pronouns, eval_avoids_absolutes, e...   \n",
       "1  [eval_acronym_consistency, eval_avoid_pronouns...   \n",
       "2  [eval_avoids_purpose_phrases, eval_consistent_...   \n",
       "3  [eval_acronym_consistency, eval_avoids_absolut...   \n",
       "4  [eval_avoid_pronouns, eval_avoids_absolutes, e...   \n",
       "\n",
       "                               failed_evals_rule_ids  \n",
       "0  [Completeness, Realism, Abstraction, Accuracy,...  \n",
       "1  [Uniformity_Of_Language, Completeness, Realism...  \n",
       "2  [Abstraction, Quantification, Uniformity_Of_La...  \n",
       "3  [Uniformity_Of_Language, Realism, Abstraction,...  \n",
       "4  [Completeness, Realism, Abstraction, Accuracy,...  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430e9ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response 1:\n",
      "{'id': 'chatcmpl-CFQTm4lqFKEQPcrFQ1kFvGCtbIFSb', 'choices': [ParsedChoice[Revision](finish_reason='stop', index=0, logprobs=None, message=ParsedChatCompletionMessage[Revision](content='{\"requirement_id\":0,\"requirement\":\"The Disputes System shall record the name of the user and the date for any activity that creates or modifies the disputes case in the system. A detailed history of the actions taken on the case including the date and the user that performed the action must be maintained for auditing purposes.\",\"revision\":\"The Disputes System shall record the following for each activity that creates or modifies a disputes case: the name of the user, the date of the action, and a detailed history of all actions taken on the case, including the date and the user responsible for each action. This history must be maintained for auditing purposes.\",\"review\":\"The original requirement was restructured for clarity and to ensure it is atomic. The revision breaks down the requirement more systematically, specifying exactly what details must be recorded for each action related to disputes cases, improving readability and understanding. It uses an active voice, maintains a positive statement structure, and clearly articulates the requirement in a way that aligns with measurable outcomes for audit purposes.\"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Revision(requirement_id=0, requirement='The Disputes System shall record the name of the user and the date for any activity that creates or modifies the disputes case in the system. A detailed history of the actions taken on the case including the date and the user that performed the action must be maintained for auditing purposes.', revision='The Disputes System shall record the following for each activity that creates or modifies a disputes case: the name of the user, the date of the action, and a detailed history of all actions taken on the case, including the date and the user responsible for each action. This history must be maintained for auditing purposes.', review='The original requirement was restructured for clarity and to ensure it is atomic. The revision breaks down the requirement more systematically, specifying exactly what details must be recorded for each action related to disputes cases, improving readability and understanding. It uses an active voice, maintains a positive statement structure, and clearly articulates the requirement in a way that aligns with measurable outcomes for audit purposes.')))], 'created': 1757792742, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'service_tier': 'default', 'system_fingerprint': 'fp_560af6e559', 'usage': CompletionUsage(completion_tokens=209, prompt_tokens=611, total_tokens=820, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), 'completion_tokens': 209, 'prompt_tokens': 611, 'total_tokens': 820, 'completion_tokens_details': CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), 'prompt_tokens_details': PromptTokensDetails(audio_tokens=0, cached_tokens=0), 'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0, 'cached_tokens': 0, 'requirement_id': 0, 'requirement': 'The Disputes System shall record the name of the user and the date for any activity that creates or modifies the disputes case in the system. A detailed history of the actions taken on the case including the date and the user that performed the action must be maintained for auditing purposes.', 'revision': 'The Disputes System shall record the following for each activity that creates or modifies a disputes case: the name of the user, the date of the action, and a detailed history of all actions taken on the case, including the date and the user responsible for each action. This history must be maintained for auditing purposes.', 'review': 'The original requirement was restructured for clarity and to ensure it is atomic. The revision breaks down the requirement more systematically, specifying exactly what details must be recorded for each action related to disputes cases, improving readability and understanding. It uses an active voice, maintains a positive statement structure, and clearly articulates the requirement in a way that aligns with measurable outcomes for audit purposes.'}\n",
      "\n",
      "Response 2:\n",
      "{'id': 'chatcmpl-CFQTm0x7TD4hGS8AIKXxyAks2ptg8', 'choices': [ParsedChoice[Revision](finish_reason='stop', index=0, logprobs=None, message=ParsedChatCompletionMessage[Revision](content='{\"requirement_id\":1,\"requirement\":\"The WCS system shall use appropriate nomenclature and terminology as defined by the Corporate Community Grants organization. All interfaces and reports will undergo usability tests by CCR users.\",\"revision\":\"The WCS system shall apply the nomenclature and terminology specified by the Corporate Community Grants organization. Usability tests shall be conducted on all interfaces and reports by users from the Corporate Community Grants organization.\",\"review\":\"1. Yes - The requirement clearly specifies terms to be used and actions to be taken. \\\\n2. Yes - The requirement is understandable to both technical and non-technical stakeholders, with clear definitions referenced. \\\\n3. No - The term \\'nomenclature\\' could be considered jargon; it\\'s not defined here. \\\\n4. Yes - The requirement uses active voice: \\'The WCS system shall...\\'. \\\\n5. Yes - There are no subjective terms present. \\\\n6. No - The requirement contains two statements: use of terminology and usability testing, which should be separated. \\\\n7. No - The requirement combines two capabilities: nomenclature application and usability testing. \\\\n8. No - The requirement includes multiple functionalities: the use of terminology and usability testing. \\\\n9. Yes - The original requirement is complex and should be split for clarity. \\\\n10. Yes - The usability testing can be verified through testing processes. \\\\n11. No - Acceptance criteria for usability tests are not specified. \\\\n12. Yes - Testers can verify if the requirement is met by reviewing documentation and testing outcomes. \\\\n13. Yes - The terminology used is consistent with organizational definitions. \\\\n14. No - Key terms like \\'nomenclature\\' are not defined in the requirement itself. \\\\n15. No - There are no immediate conflicts identified with other requirements, but clarity could reduce ambiguity. \\\\n16. Yes - The requirement aligns with stakeholder needs for consistency in terminology. \\\\n17. Yes - The requirement adds value by ensuring communication clarity and usability. \\\\n18. No - The rationale is not articulated; further explanation of why this requirement exists would be helpful. \\\\n19. No - It lacks detail on the conditions under which the usability tests will occur. \\\\n20. Yes - The clause appears implementable given common industry practices.\"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Revision(requirement_id=1, requirement='The WCS system shall use appropriate nomenclature and terminology as defined by the Corporate Community Grants organization. All interfaces and reports will undergo usability tests by CCR users.', revision='The WCS system shall apply the nomenclature and terminology specified by the Corporate Community Grants organization. Usability tests shall be conducted on all interfaces and reports by users from the Corporate Community Grants organization.', review=\"1. Yes - The requirement clearly specifies terms to be used and actions to be taken. \\n2. Yes - The requirement is understandable to both technical and non-technical stakeholders, with clear definitions referenced. \\n3. No - The term 'nomenclature' could be considered jargon; it's not defined here. \\n4. Yes - The requirement uses active voice: 'The WCS system shall...'. \\n5. Yes - There are no subjective terms present. \\n6. No - The requirement contains two statements: use of terminology and usability testing, which should be separated. \\n7. No - The requirement combines two capabilities: nomenclature application and usability testing. \\n8. No - The requirement includes multiple functionalities: the use of terminology and usability testing. \\n9. Yes - The original requirement is complex and should be split for clarity. \\n10. Yes - The usability testing can be verified through testing processes. \\n11. No - Acceptance criteria for usability tests are not specified. \\n12. Yes - Testers can verify if the requirement is met by reviewing documentation and testing outcomes. \\n13. Yes - The terminology used is consistent with organizational definitions. \\n14. No - Key terms like 'nomenclature' are not defined in the requirement itself. \\n15. No - There are no immediate conflicts identified with other requirements, but clarity could reduce ambiguity. \\n16. Yes - The requirement aligns with stakeholder needs for consistency in terminology. \\n17. Yes - The requirement adds value by ensuring communication clarity and usability. \\n18. No - The rationale is not articulated; further explanation of why this requirement exists would be helpful. \\n19. No - It lacks detail on the conditions under which the usability tests will occur. \\n20. Yes - The clause appears implementable given common industry practices.\")))], 'created': 1757792742, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'service_tier': 'default', 'system_fingerprint': 'fp_560af6e559', 'usage': CompletionUsage(completion_tokens=470, prompt_tokens=585, total_tokens=1055, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), 'completion_tokens': 470, 'prompt_tokens': 585, 'total_tokens': 1055, 'completion_tokens_details': CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), 'prompt_tokens_details': PromptTokensDetails(audio_tokens=0, cached_tokens=0), 'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0, 'cached_tokens': 0, 'requirement_id': 1, 'requirement': 'The WCS system shall use appropriate nomenclature and terminology as defined by the Corporate Community Grants organization. All interfaces and reports will undergo usability tests by CCR users.', 'revision': 'The WCS system shall apply the nomenclature and terminology specified by the Corporate Community Grants organization. Usability tests shall be conducted on all interfaces and reports by users from the Corporate Community Grants organization.', 'review': \"1. Yes - The requirement clearly specifies terms to be used and actions to be taken. \\n2. Yes - The requirement is understandable to both technical and non-technical stakeholders, with clear definitions referenced. \\n3. No - The term 'nomenclature' could be considered jargon; it's not defined here. \\n4. Yes - The requirement uses active voice: 'The WCS system shall...'. \\n5. Yes - There are no subjective terms present. \\n6. No - The requirement contains two statements: use of terminology and usability testing, which should be separated. \\n7. No - The requirement combines two capabilities: nomenclature application and usability testing. \\n8. No - The requirement includes multiple functionalities: the use of terminology and usability testing. \\n9. Yes - The original requirement is complex and should be split for clarity. \\n10. Yes - The usability testing can be verified through testing processes. \\n11. No - Acceptance criteria for usability tests are not specified. \\n12. Yes - Testers can verify if the requirement is met by reviewing documentation and testing outcomes. \\n13. Yes - The terminology used is consistent with organizational definitions. \\n14. No - Key terms like 'nomenclature' are not defined in the requirement itself. \\n15. No - There are no immediate conflicts identified with other requirements, but clarity could reduce ambiguity. \\n16. Yes - The requirement aligns with stakeholder needs for consistency in terminology. \\n17. Yes - The requirement adds value by ensuring communication clarity and usability. \\n18. No - The rationale is not articulated; further explanation of why this requirement exists would be helpful. \\n19. No - It lacks detail on the conditions under which the usability tests will occur. \\n20. Yes - The clause appears implementable given common industry practices.\"}\n",
      "\n",
      "Response 3:\n",
      "{'id': 'chatcmpl-CFQTlfJz17czJjm3SpLQB29eT8MYl', 'choices': [ParsedChoice[Revision](finish_reason='stop', index=0, logprobs=None, message=ParsedChatCompletionMessage[Revision](content='{\"requirement_id\":2,\"requirement\":\"The system will notify affected parties when changes occur affecting clinicals, including but not limited to clinical section capacity changes and clinical section cancellations.\",\"revision\":\"The system shall notify all affected parties immediately upon changes affecting clinical sections, including changes in capacity and cancellations, ensuring timely communication.\",\"review\":\"The original requirement was revised to improve clarity and alignment with the checklist criteria. Changes included using \\'shall\\' instead of \\'will\\' to specify obligation (active voice), rephrasing for conciseness, and eliminating vague terms. The language was clarified to ensure all terms (like \\'affected parties\\' and \\'clinical sections\\') are understandable. The requirement was made more direct and explicit about timing (\\'immediately\\') to enhance verifiability. Overall, the revision aimed to enhance clarity, specificity, and adherence to best practices in requirements writing.\"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Revision(requirement_id=2, requirement='The system will notify affected parties when changes occur affecting clinicals, including but not limited to clinical section capacity changes and clinical section cancellations.', revision='The system shall notify all affected parties immediately upon changes affecting clinical sections, including changes in capacity and cancellations, ensuring timely communication.', review=\"The original requirement was revised to improve clarity and alignment with the checklist criteria. Changes included using 'shall' instead of 'will' to specify obligation (active voice), rephrasing for conciseness, and eliminating vague terms. The language was clarified to ensure all terms (like 'affected parties' and 'clinical sections') are understandable. The requirement was made more direct and explicit about timing ('immediately') to enhance verifiability. Overall, the revision aimed to enhance clarity, specificity, and adherence to best practices in requirements writing.\")))], 'created': 1757792741, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'service_tier': 'default', 'system_fingerprint': 'fp_560af6e559', 'usage': CompletionUsage(completion_tokens=175, prompt_tokens=582, total_tokens=757, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), 'completion_tokens': 175, 'prompt_tokens': 582, 'total_tokens': 757, 'completion_tokens_details': CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), 'prompt_tokens_details': PromptTokensDetails(audio_tokens=0, cached_tokens=0), 'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0, 'cached_tokens': 0, 'requirement_id': 2, 'requirement': 'The system will notify affected parties when changes occur affecting clinicals, including but not limited to clinical section capacity changes and clinical section cancellations.', 'revision': 'The system shall notify all affected parties immediately upon changes affecting clinical sections, including changes in capacity and cancellations, ensuring timely communication.', 'review': \"The original requirement was revised to improve clarity and alignment with the checklist criteria. Changes included using 'shall' instead of 'will' to specify obligation (active voice), rephrasing for conciseness, and eliminating vague terms. The language was clarified to ensure all terms (like 'affected parties' and 'clinical sections') are understandable. The requirement was made more direct and explicit about timing ('immediately') to enhance verifiability. Overall, the revision aimed to enhance clarity, specificity, and adherence to best practices in requirements writing.\"}\n",
      "\n",
      "Response 4:\n",
      "{'id': 'chatcmpl-CFQTl173N1ooshvmu1Yu0t50h1V5B', 'choices': [ParsedChoice[Revision](finish_reason='stop', index=0, logprobs=None, message=ParsedChatCompletionMessage[Revision](content='{\"requirement_id\":3,\"requirement\":\"Application testability DESC: Test environments should be built for the application to allow testing of the applications different functions.\",\"revision\":\"The system shall provide test environments that enable the testing of all application functionalities.\",\"review\":\"The original requirement was vague and did not specify what constitutes \\'test environments\\' or \\'functions\\'. The revision clarifies that the system must provide \\'test environments\\', using active voice and a clearer structure. This addresses the ambiguity and enhances understanding while making it measurable. The revised requirement can be verified through testing of the environments provided.\"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Revision(requirement_id=3, requirement='Application testability DESC: Test environments should be built for the application to allow testing of the applications different functions.', revision='The system shall provide test environments that enable the testing of all application functionalities.', review=\"The original requirement was vague and did not specify what constitutes 'test environments' or 'functions'. The revision clarifies that the system must provide 'test environments', using active voice and a clearer structure. This addresses the ambiguity and enhances understanding while making it measurable. The revised requirement can be verified through testing of the environments provided.\")))], 'created': 1757792741, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'service_tier': 'default', 'system_fingerprint': 'fp_560af6e559', 'usage': CompletionUsage(completion_tokens=117, prompt_tokens=576, total_tokens=693, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), 'completion_tokens': 117, 'prompt_tokens': 576, 'total_tokens': 693, 'completion_tokens_details': CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), 'prompt_tokens_details': PromptTokensDetails(audio_tokens=0, cached_tokens=0), 'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0, 'cached_tokens': 0, 'requirement_id': 3, 'requirement': 'Application testability DESC: Test environments should be built for the application to allow testing of the applications different functions.', 'revision': 'The system shall provide test environments that enable the testing of all application functionalities.', 'review': \"The original requirement was vague and did not specify what constitutes 'test environments' or 'functions'. The revision clarifies that the system must provide 'test environments', using active voice and a clearer structure. This addresses the ambiguity and enhances understanding while making it measurable. The revised requirement can be verified through testing of the environments provided.\"}\n",
      "\n",
      "Response 5:\n",
      "{'id': 'chatcmpl-CFQTl0vx5Twe0yYh21nuHX4skQeXR', 'choices': [ParsedChoice[Revision](finish_reason='stop', index=0, logprobs=None, message=ParsedChatCompletionMessage[Revision](content='{\"requirement_id\":4,\"requirement\":\"The product shall be platform independent. The product shall enable access to any type of development environment and platform.\",\"revision\":\"The product shall be platform independent, allowing access to all types of development environments and platforms.\",\"review\":\"1. Yes - The requirement clearly states the need for platform independence and access to various environments.\\\\n2. Yes - The phrasing is straightforward, allowing both technical and non-technical readers to comprehend.\\\\n3. Yes - It uses plain language without jargon or acronyms.\\\\n4. Yes - It uses active voice with a positive structure.\\\\n5. Yes - There are no subjective terms in the requirement.\\\\n6. No - The original requirement combines two statements into one.\\\\n7. No - It addresses two capabilities: platform independence and access.\\\\n8. No - The original requirement is compound.\\\\n9. Yes - I split the compound requirement into a single focused requirement in the revision.\\\\n10. Yes - The revised requirement can be verified through testing whether the product functions across platforms.\\\\n11. No - Acceptance criteria could be clearer; they aren\\'t explicitly stated in the original.\\\\n12. Yes - A tester can measure if both capabilities are met based on the revision.\\\\n13. Yes - The terminology is consistent with typical requirements documentation.\\\\n14. No - Key terms like \\\\\"platform independent\\\\\" might need definitions depending on the context.\\\\n15. No - There doesn\\'t appear to be conflicting wording compared to similar requirements.\\\\n16. Yes - It aligns with stakeholder needs for versatility in development environments.\\\\n17. Yes - The requirement adds value by broadening usability across platforms.\\\\n18. No - The rationale for the requirement is not documented.\\\\n19. No - The requirement does not specify conditions like operating constraints or performance parameters.\\\\n20. Yes - It is implementable within typical project constraints.\"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Revision(requirement_id=4, requirement='The product shall be platform independent. The product shall enable access to any type of development environment and platform.', revision='The product shall be platform independent, allowing access to all types of development environments and platforms.', review='1. Yes - The requirement clearly states the need for platform independence and access to various environments.\\n2. Yes - The phrasing is straightforward, allowing both technical and non-technical readers to comprehend.\\n3. Yes - It uses plain language without jargon or acronyms.\\n4. Yes - It uses active voice with a positive structure.\\n5. Yes - There are no subjective terms in the requirement.\\n6. No - The original requirement combines two statements into one.\\n7. No - It addresses two capabilities: platform independence and access.\\n8. No - The original requirement is compound.\\n9. Yes - I split the compound requirement into a single focused requirement in the revision.\\n10. Yes - The revised requirement can be verified through testing whether the product functions across platforms.\\n11. No - Acceptance criteria could be clearer; they aren\\'t explicitly stated in the original.\\n12. Yes - A tester can measure if both capabilities are met based on the revision.\\n13. Yes - The terminology is consistent with typical requirements documentation.\\n14. No - Key terms like \"platform independent\" might need definitions depending on the context.\\n15. No - There doesn\\'t appear to be conflicting wording compared to similar requirements.\\n16. Yes - It aligns with stakeholder needs for versatility in development environments.\\n17. Yes - The requirement adds value by broadening usability across platforms.\\n18. No - The rationale for the requirement is not documented.\\n19. No - The requirement does not specify conditions like operating constraints or performance parameters.\\n20. Yes - It is implementable within typical project constraints.')))], 'created': 1757792741, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'service_tier': 'default', 'system_fingerprint': 'fp_560af6e559', 'usage': CompletionUsage(completion_tokens=384, prompt_tokens=573, total_tokens=957, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), 'completion_tokens': 384, 'prompt_tokens': 573, 'total_tokens': 957, 'completion_tokens_details': CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), 'prompt_tokens_details': PromptTokensDetails(audio_tokens=0, cached_tokens=0), 'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0, 'cached_tokens': 0, 'requirement_id': 4, 'requirement': 'The product shall be platform independent. The product shall enable access to any type of development environment and platform.', 'revision': 'The product shall be platform independent, allowing access to all types of development environments and platforms.', 'review': '1. Yes - The requirement clearly states the need for platform independence and access to various environments.\\n2. Yes - The phrasing is straightforward, allowing both technical and non-technical readers to comprehend.\\n3. Yes - It uses plain language without jargon or acronyms.\\n4. Yes - It uses active voice with a positive structure.\\n5. Yes - There are no subjective terms in the requirement.\\n6. No - The original requirement combines two statements into one.\\n7. No - It addresses two capabilities: platform independence and access.\\n8. No - The original requirement is compound.\\n9. Yes - I split the compound requirement into a single focused requirement in the revision.\\n10. Yes - The revised requirement can be verified through testing whether the product functions across platforms.\\n11. No - Acceptance criteria could be clearer; they aren\\'t explicitly stated in the original.\\n12. Yes - A tester can measure if both capabilities are met based on the revision.\\n13. Yes - The terminology is consistent with typical requirements documentation.\\n14. No - Key terms like \"platform independent\" might need definitions depending on the context.\\n15. No - There doesn\\'t appear to be conflicting wording compared to similar requirements.\\n16. Yes - It aligns with stakeholder needs for versatility in development environments.\\n17. Yes - The requirement adds value by broadening usability across platforms.\\n18. No - The rationale for the requirement is not documented.\\n19. No - The requirement does not specify conditions like operating constraints or performance parameters.\\n20. Yes - It is implementable within typical project constraints.'}\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import asyncio\n",
    "from pydantic import BaseModel, Field, SecretStr\n",
    "from src.components.promptrunner import RateLimitOpenAIClient\n",
    "# Run prompt for requirements containing failed evaluations (asychronously with retry and backoff to overcome rate limit errors)\n",
    "openai_api_key = SecretStr(str(DOT_ENV['OPENAI_API_KEY']))\n",
    "openai_client = RateLimitOpenAIClient(api_key=openai_api_key.get_secret_value())\n",
    "# Define data validation model\n",
    "class Revision(BaseModel):\n",
    "    requirement_id: int = Field(description=\"The original requirement id provided by the user\")\n",
    "    requirement: str = Field(description=\"The original requirement provided by the user\")\n",
    "    revision: str = Field(description=\"The revised AI-generated output requirement\")\n",
    "    review: str = Field(description=\"A summary of the thought process used to generate the revision and why it was chosen\") \n",
    "\n",
    "# Example usage\n",
    "async def run_reviewer_prompts(requirements, ids, model: str = 'gpt-4o-mini', ):\n",
    "       \n",
    "    req_tups = zip(requirements, ids)\n",
    "    # Example of making multiple concurrent requests\n",
    "    tasks = []\n",
    "    for i, req_tup in enumerate(req_tups):\n",
    "        tasks.append(\n",
    "            openai_client.chat_completion_parse(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\":\"system\", \"content\": 'You are a meticulous requirements analyst tasked with verifying the quality and clarity of a given requirement based on a detailed checklist.'},\n",
    "                    {\"role\":\"user\", \"content\": f'Given the following id and requirement:\\n\\n\"\"\"\\nrequirement_id:{req_tup[1]} requirement:{req_tup[0]}\\n\"\"\"\\n\\nPlease systematically assess the requirement against each of the following criteria, providing a clear answer (Yes/No) and a concise explanation for each:\\n\\n1. Is the requirement clearly stated, avoiding ambiguous or vague terms?\\n2. Can all readers (technical and non-technical stakeholders) understand the requirement without confusion?\\n3. Is it written in plain, simple language with no jargon or undefined acronyms?\\n4. Does the requirement use active voice and a positive statement (e.g., \\'The system shallâ€¦\\')?\\n5. Does it avoid subjective words such as \\'user-friendly\\', \\'fast\\', or \\'optimal\\'?\\n6. Is the requirement phrased as a single, atomic statement (not combining multiple requirements)?\\n7. Does the requirement address a single capability or attribute?\\n8. Avoid compound requirements that include more than one functionality or condition.\\n9. Split complex requirements into multiple focused ones if necessary.\\n10. Is the requirement stated in such a way that it can be verified through test, inspection, or analysis?\\n11. Are the acceptance criteria or measurable parameters clearly indicated or implied?\\n12. Could a tester or analyst objectively determine if the requirement is met or not?\\n13. Does the requirement use terminology consistent with the rest of the documentation?\\n14. Are key terms defined somewhere in a glossary or within the document?\\n15. Is there any conflicting wording when compared to other requirements?\\n16. Is the requirement traceable back to a stakeholder need, higher-level system requirement, or project objective?\\n17. Does the requirement add value to the system, or is it redundant or unnecessary?\\n18. Is the rationale for the requirement clear or documented (if applicable)?\\n19. Does the requirement cover all relevant conditions and constraints (e.g., operating environment, performance parameters)?\\n20. Is it realistically implementable within project constraints (time, cost, technology)?\\n\\nProvide your answer in a numbered list with each item corresponding to the checklist criteria.'}\n",
    "                ],\n",
    "                response_format=Revision\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Wait for all requests to complete\n",
    "    responses = await asyncio.gather(*tasks)\n",
    "    \n",
    "    # Process responses\n",
    "    processed_responses = []\n",
    "    for i, response in enumerate(responses):\n",
    "        \n",
    "        output = dict(response)\n",
    "        message = response.choices[0].message\n",
    "\n",
    "        if getattr(response, \"usage\"):\n",
    "            \n",
    "            output.update(\n",
    "                dict(response.usage)\n",
    "            )\n",
    "            \n",
    "            output.update(\n",
    "                dict(response.usage.completion_tokens_details)\n",
    "            )\n",
    "            output.update(\n",
    "                dict(response.usage.prompt_tokens_details)\n",
    "            )\n",
    "\n",
    "        if getattr(message, \"parsed\"):\n",
    "            output.update(\n",
    "                dict(message.parsed)\n",
    "            )\n",
    "        \n",
    "        print(f\"\\nResponse {i+1}:\")\n",
    "        print(output)\n",
    "        processed_responses.append(output)\n",
    "        \n",
    "    #return processed_responses\n",
    "    return processed_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ed9422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "iternum=3\n",
    "id_col = 'requirement_#'\n",
    "\n",
    "for i in range(iternum):\n",
    "    if i == 0:\n",
    "        # Load requirements\n",
    "        df = pd.read_excel('../src/data/demo_dataset.xlsx')\n",
    "        requirement_col = 'requirement'\n",
    "        # Call the evaluations on the dataframe \n",
    "        df = pe.call_evals(df, col=requirement_col, eval_config=eval_config)\n",
    "        # Get list of failed eval functions\n",
    "        df = pe.get_failed_evals(df)\n",
    "        # Map the failed eval functions to rule groups (as defined in the config.yaml file)\n",
    "        df = pe.map_failed_eval_col_to_rule_group(df, eval_to_rule_map=config[\"SECTION_4_RULE_GROUPS\"], failed_eval_col='failed_evals')   \n",
    "        # Drop requirements which pass acceptance criteria\n",
    "        # At present, the criteria is len(failed_evals_rule_ids) == 0\n",
    "        df = df.loc[df['failed_evals_rule_ids'].str.len() > 0]\n",
    "        df.to_excel(f\"{output_directory}/eval_df_initial.xlsx\")\n",
    "    else:\n",
    "        df = revisions_df.copy()\n",
    "        requirement_col = 'revision'\n",
    "\n",
    "    requirements = list(df[requirement_col].values)\n",
    "    ids = list(df[id_col].values)     \n",
    "    revisions = asyncio.run(run_reviewer_prompts(requirements, ids))\n",
    "    revisions_df = pd.DataFrame(revisions)\n",
    "    # Call the evaluations on the dataframe \n",
    "    eval_df = pe.call_evals(revisions_df, col=requirement_col, eval_config=eval_config)\n",
    "    # Get list of failed eval functions\n",
    "    eval_df = pe.get_failed_evals(eval_df)\n",
    "    # Map the failed eval functions to rule groups (as defined in the config.yaml file)\n",
    "    eval_df = pe.map_failed_eval_col_to_rule_group(eval_df, eval_to_rule_map=config[\"SECTION_4_RULE_GROUPS\"], failed_eval_col='failed_evals')\n",
    "    # Drop requirements which pass acceptance criteria\n",
    "    # At present, the criteria is len(failed_evals_rule_ids) == 0\n",
    "    eval_df = eval_df.loc[eval_df['failed_evals_rule_ids'].str.len() > 0]\n",
    "    eval_df.to_excel(f\"{output_directory}/eval_df_iter_{i+1}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e9e293f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Call the evaluations on the dataframe \n",
    "eval_df = pe.call_evals(revisions_df, col='revision', eval_config=eval_config)\n",
    "# Get list of failed eval functions\n",
    "eval_df = pe.get_failed_evals(eval_df)\n",
    "# Map the failed eval functions to rule groups (as defined in the config.yaml file)\n",
    "eval_df = pe.map_failed_eval_col_to_rule_group(eval_df, eval_to_rule_map=config[\"SECTION_4_RULE_GROUPS\"], failed_eval_col='failed_evals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32543fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>choices</th>\n",
       "      <th>created</th>\n",
       "      <th>model</th>\n",
       "      <th>object</th>\n",
       "      <th>service_tier</th>\n",
       "      <th>system_fingerprint</th>\n",
       "      <th>usage</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>...</th>\n",
       "      <th>eval_is_singular_statement</th>\n",
       "      <th>eval_is_solution_free</th>\n",
       "      <th>eval_logical_expressions</th>\n",
       "      <th>eval_no_oblique_symbol</th>\n",
       "      <th>eval_terms_are_defined</th>\n",
       "      <th>eval_uses_abbreviations</th>\n",
       "      <th>eval_uses_not</th>\n",
       "      <th>eval_uses_universal_qualification</th>\n",
       "      <th>failed_evals</th>\n",
       "      <th>failed_evals_rule_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chatcmpl-CFQTm4lqFKEQPcrFQ1kFvGCtbIFSb</td>\n",
       "      <td>[ParsedChoice[Revision](finish_reason='stop', ...</td>\n",
       "      <td>1757792742</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>default</td>\n",
       "      <td>fp_560af6e559</td>\n",
       "      <td>CompletionUsage(completion_tokens=209, prompt_...</td>\n",
       "      <td>209</td>\n",
       "      <td>611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[eval_avoid_pronouns, eval_avoids_absolutes, e...</td>\n",
       "      <td>[Completeness, Realism, Abstraction, Quantific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chatcmpl-CFQTm0x7TD4hGS8AIKXxyAks2ptg8</td>\n",
       "      <td>[ParsedChoice[Revision](finish_reason='stop', ...</td>\n",
       "      <td>1757792742</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>default</td>\n",
       "      <td>fp_560af6e559</td>\n",
       "      <td>CompletionUsage(completion_tokens=470, prompt_...</td>\n",
       "      <td>470</td>\n",
       "      <td>585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[eval_acronym_consistency, eval_avoid_pronouns...</td>\n",
       "      <td>[Uniformity_Of_Language, Completeness, Realism...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chatcmpl-CFQTlfJz17czJjm3SpLQB29eT8MYl</td>\n",
       "      <td>[ParsedChoice[Revision](finish_reason='stop', ...</td>\n",
       "      <td>1757792741</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>default</td>\n",
       "      <td>fp_560af6e559</td>\n",
       "      <td>CompletionUsage(completion_tokens=175, prompt_...</td>\n",
       "      <td>175</td>\n",
       "      <td>582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[eval_avoid_pronouns, eval_avoids_absolutes, e...</td>\n",
       "      <td>[Completeness, Realism, Quantification, Unifor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chatcmpl-CFQTl173N1ooshvmu1Yu0t50h1V5B</td>\n",
       "      <td>[ParsedChoice[Revision](finish_reason='stop', ...</td>\n",
       "      <td>1757792741</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>default</td>\n",
       "      <td>fp_560af6e559</td>\n",
       "      <td>CompletionUsage(completion_tokens=117, prompt_...</td>\n",
       "      <td>117</td>\n",
       "      <td>576</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[eval_avoid_pronouns, eval_avoids_absolutes, e...</td>\n",
       "      <td>[Completeness, Realism, Quantification, Modula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chatcmpl-CFQTl0vx5Twe0yYh21nuHX4skQeXR</td>\n",
       "      <td>[ParsedChoice[Revision](finish_reason='stop', ...</td>\n",
       "      <td>1757792741</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>default</td>\n",
       "      <td>fp_560af6e559</td>\n",
       "      <td>CompletionUsage(completion_tokens=384, prompt_...</td>\n",
       "      <td>384</td>\n",
       "      <td>573</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[eval_avoid_pronouns, eval_avoids_absolutes, e...</td>\n",
       "      <td>[Completeness, Realism, Abstraction, Quantific...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id  \\\n",
       "0  chatcmpl-CFQTm4lqFKEQPcrFQ1kFvGCtbIFSb   \n",
       "1  chatcmpl-CFQTm0x7TD4hGS8AIKXxyAks2ptg8   \n",
       "2  chatcmpl-CFQTlfJz17czJjm3SpLQB29eT8MYl   \n",
       "3  chatcmpl-CFQTl173N1ooshvmu1Yu0t50h1V5B   \n",
       "4  chatcmpl-CFQTl0vx5Twe0yYh21nuHX4skQeXR   \n",
       "\n",
       "                                             choices     created  \\\n",
       "0  [ParsedChoice[Revision](finish_reason='stop', ...  1757792742   \n",
       "1  [ParsedChoice[Revision](finish_reason='stop', ...  1757792742   \n",
       "2  [ParsedChoice[Revision](finish_reason='stop', ...  1757792741   \n",
       "3  [ParsedChoice[Revision](finish_reason='stop', ...  1757792741   \n",
       "4  [ParsedChoice[Revision](finish_reason='stop', ...  1757792741   \n",
       "\n",
       "                    model           object service_tier system_fingerprint  \\\n",
       "0  gpt-4o-mini-2024-07-18  chat.completion      default      fp_560af6e559   \n",
       "1  gpt-4o-mini-2024-07-18  chat.completion      default      fp_560af6e559   \n",
       "2  gpt-4o-mini-2024-07-18  chat.completion      default      fp_560af6e559   \n",
       "3  gpt-4o-mini-2024-07-18  chat.completion      default      fp_560af6e559   \n",
       "4  gpt-4o-mini-2024-07-18  chat.completion      default      fp_560af6e559   \n",
       "\n",
       "                                               usage  completion_tokens  \\\n",
       "0  CompletionUsage(completion_tokens=209, prompt_...                209   \n",
       "1  CompletionUsage(completion_tokens=470, prompt_...                470   \n",
       "2  CompletionUsage(completion_tokens=175, prompt_...                175   \n",
       "3  CompletionUsage(completion_tokens=117, prompt_...                117   \n",
       "4  CompletionUsage(completion_tokens=384, prompt_...                384   \n",
       "\n",
       "   prompt_tokens  ...  eval_is_singular_statement eval_is_solution_free  \\\n",
       "0            611  ...                         0.0                   0.0   \n",
       "1            585  ...                         0.0                   0.0   \n",
       "2            582  ...                         0.0                   1.0   \n",
       "3            576  ...                         1.0                   1.0   \n",
       "4            573  ...                         1.0                   0.0   \n",
       "\n",
       "  eval_logical_expressions  eval_no_oblique_symbol  eval_terms_are_defined  \\\n",
       "0                      0.0                     1.0                     1.0   \n",
       "1                      0.0                     1.0                     0.0   \n",
       "2                      0.0                     1.0                     1.0   \n",
       "3                      1.0                     1.0                     1.0   \n",
       "4                      0.0                     1.0                     1.0   \n",
       "\n",
       "   eval_uses_abbreviations  eval_uses_not  eval_uses_universal_qualification  \\\n",
       "0                      1.0            1.0                                0.0   \n",
       "1                      0.0            1.0                                0.0   \n",
       "2                      1.0            0.0                                0.0   \n",
       "3                      1.0            1.0                                0.0   \n",
       "4                      1.0            1.0                                0.0   \n",
       "\n",
       "                                        failed_evals  \\\n",
       "0  [eval_avoid_pronouns, eval_avoids_absolutes, e...   \n",
       "1  [eval_acronym_consistency, eval_avoid_pronouns...   \n",
       "2  [eval_avoid_pronouns, eval_avoids_absolutes, e...   \n",
       "3  [eval_avoid_pronouns, eval_avoids_absolutes, e...   \n",
       "4  [eval_avoid_pronouns, eval_avoids_absolutes, e...   \n",
       "\n",
       "                               failed_evals_rule_ids  \n",
       "0  [Completeness, Realism, Abstraction, Quantific...  \n",
       "1  [Uniformity_Of_Language, Completeness, Realism...  \n",
       "2  [Completeness, Realism, Quantification, Unifor...  \n",
       "3  [Completeness, Realism, Quantification, Modula...  \n",
       "4  [Completeness, Realism, Abstraction, Quantific...  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
